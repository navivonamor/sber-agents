# Техническое видение проекта: LLM-ассистент "Кулинарный помощник"

## Технологии

### Язык программирования
- **Python 3.11+** — основной язык разработки

### Управление зависимостями
- **uv** — быстрый менеджер пакетов и проектов для Python

### Основные библиотеки
- **openai** — клиент для работы с LLM через провайдер OpenRouter
- **aiogram 3.x** — асинхронный фреймворк для Telegram Bot API
  - Использование метода **polling** для получения обновлений

### Инструменты сборки
- **make** — автоматизация задач проекта (запуск, тестирование, сборка)

## Принцип разработки

### Основные принципы
- **KISS (Keep It Simple, Stupid)** — максимально простые решения, без лишних абстракций
- **YAGNI (You Aren't Gonna Need It)** — реализуем только то, что нужно сейчас для проверки идеи

### Подход
- Минималистичная архитектура — без избыточного оверинжиниринга
- Простая структура кода — минимальное количество файлов и модулей
- In-memory хранение — без использования базы данных на первом этапе
- Фокус на основной функции — ведение диалога с ролью "Кулинарный помощник"

## Структура проекта

```
03-aidd/
├── docs/
│   ├── idea.md             # Описание идеи проекта
│   └── vision.md           # Техническое видение проекта
├── src/
│   └── bot.py              # Основной файл бота (вся логика в одном файле)
├── pyproject.toml          # Конфигурация uv проекта и зависимости
├── .env.example            # Пример файла с переменными окружения
├── .env                    # Файл с переменными окружения (не коммитится)
├── Makefile                # Команды для сборки и запуска проекта
├── .gitignore              # Игнорируемые файлы
└── README.md               # Документация проекта
```

### Описание файлов
- `src/bot.py` — вся логика бота: обработка сообщений, работа с LLM, управление диалогом
- `pyproject.toml` — конфигурация проекта, зависимости, настройки uv
- `.env` — переменные окружения (токен бота, API ключ OpenRouter)
- `Makefile` — простые команды: `make run`, `make install`

## Архитектура проекта

### Компоненты

1. **Точка входа** (`bot.py`)
   - Инициализация бота и диспетчера aiogram
   - Запуск polling

2. **Telegram Handler**
   - Обработка всех текстовых сообщений от пользователей
   - Отправка ответов пользователям

3. **LLM Client**
   - Клиент OpenAI для работы с OpenRouter
   - Формирование запросов с системным промптом и историей диалога

4. **Dialog Manager** (in-memory)
   - Хранение истории диалога в словаре: `{chat_id: [messages]}`
   - Добавление новых сообщений в историю
   - Очистка истории (по команде или при ошибках)

### Поток работы

```
Пользователь отправляет сообщение
    ↓
Telegram Handler получает сообщение
    ↓
Dialog Manager добавляет сообщение пользователя в историю
    ↓
LLM Client формирует запрос с системным промптом и историей
    ↓
OpenRouter → LLM генерирует ответ
    ↓
Dialog Manager сохраняет ответ в историю
    ↓
Telegram Handler отправляет ответ пользователю
```

### Особенности
- Все компоненты в одном файле `bot.py`
- Простая обработка ошибок (логирование и уведомление пользователя)
- Ограничение истории диалога (последние N сообщений) для контроля токенов

## Модель данных

### Хранение истории диалога

**Структура:** `dict[int, list[dict]]`

- **Ключ:** `chat_id` (int) — ID чата Telegram
- **Значение:** список сообщений в формате OpenAI API

**Формат сообщения:**
```python
{
    "role": "user" | "assistant",
    "content": "текст сообщения"
}
```

### Системный промпт

Простая строка с описанием роли:
```
"Ты — кулинарный помощник. Помогаешь пользователям с вопросами о приготовлении пищи, рецептах, кулинарных техниках и всем, что связано с кулинарией."
```

### Ограничения

- Максимальная длина истории: последние **10 сообщений** (5 пар вопрос-ответ)
- При превышении лимита удаляются самые старые сообщения (кроме системного промпта)

## Работа с LLM

### Провайдер и клиент

- **Провайдер:** OpenRouter
- **Клиент:** OpenAI Python client (совместимый API)
- **Endpoint:** `https://openrouter.ai/api/v1/chat/completions`

### Конфигурация

- **API ключ:** переменная окружения `OPENROUTER_API_KEY`
- **Модель:** переменная окружения `LLM_MODEL` (например, `anthropic/claude-3-haiku`, `openai/gpt-3.5-turbo`)
- **Температура:** `0.7` (фиксированное значение для стабильности ответов)
- **Max tokens:** значение по умолчанию модели

### Формирование запроса

1. Системный промпт добавляется первым сообщением с `role: "system"`
2. История диалога добавляется как список сообщений с `role: "user"` и `role: "assistant"`
3. Новое сообщение пользователя добавляется с `role: "user"`

### Обработка ответа

- Извлечение текста из `response.choices[0].message.content`
- Простая обработка ошибок: логирование и уведомление пользователя при сбоях

## Сценарии работы

### Сценарий 1: Первое сообщение пользователя

1. Пользователь отправляет текстовое сообщение боту
2. Бот создает новую историю диалога для пользователя
3. Системный промпт + сообщение пользователя отправляется в LLM
4. Бот получает ответ от LLM
5. Ответ сохраняется в историю диалога
6. Бот отправляет ответ пользователю

### Сценарий 2: Продолжение диалога

1. Пользователь отправляет новое сообщение
2. Сообщение добавляется в существующую историю диалога
3. Если история превышает лимит (10 сообщений), удаляются старые
4. Полная история (системный промпт + все сообщения) отправляется в LLM
5. Бот получает ответ с учетом контекста предыдущих сообщений
6. Ответ сохраняется и отправляется пользователю

### Сценарий 3: Очистка истории диалога

1. Пользователь отправляет команду `/reset`
2. Бот очищает историю диалога для этого пользователя
3. Бот отправляет подтверждение: "История диалога очищена. Начнем заново!"

### Сценарий 4: Обработка ошибок

1. При ошибке запроса к LLM (таймаут, недоступность, ошибка API)
2. Бот логирует ошибку
3. Бот отправляет пользователю сообщение: "Извините, произошла ошибка. Попробуйте еще раз."

### Команды бота

- `/start` — приветственное сообщение и краткое описание бота
- `/reset` — очистка истории диалога
- Любое текстовое сообщение — вопрос к кулинарному помощнику

## Подход к конфигурированию

### Переменные окружения

Все настройки хранятся в файле `.env`:

```env
TELEGRAM_BOT_TOKEN=your_telegram_bot_token
OPENROUTER_API_KEY=your_openrouter_api_key
LLM_MODEL=anthropic/claude-3-haiku
```

### Загрузка конфигурации

- Использование библиотеки `python-dotenv` для загрузки переменных из `.env`
- Загрузка при старте приложения
- Проверка наличия обязательных переменных (выброс ошибки при отсутствии)

### Настройки в коде

- **Системный промпт** — константа в коде (для простоты)
- **Температура LLM** — константа `0.7`
- **Лимит истории** — константа `10 сообщений`

### Файл `.env.example`

Шаблон с примерами значений (без реальных ключей) для документации:
```env
TELEGRAM_BOT_TOKEN=your_telegram_bot_token_here
OPENROUTER_API_KEY=your_openrouter_api_key_here
LLM_MODEL=anthropic/claude-3-haiku
```

## Подход к логгированию

### Библиотека и настройка

- **Библиотека:** встроенный модуль `logging` (Python)
- **Уровень логирования:** `INFO` (по умолчанию)
- **Формат:** `%(asctime)s - %(name)s - %(levelname)s - %(message)s`
- **Вывод:** консоль (stdout)

### События для логирования

1. **Запуск/остановка бота**
   - `INFO`: "Бот запущен"
   - `INFO`: "Бот остановлен"

2. **Обработка сообщений**
   - `INFO`: "Получено сообщение из чата {chat_id}"
   - `INFO`: "Отправлен ответ в чат {chat_id}"

3. **Работа с LLM**
   - `INFO`: "Запрос к LLM (модель: {model}, история: {len(history)} сообщений)"
   - `INFO`: "Получен ответ от LLM (длина: {len(response)} символов)"

4. **Ошибки**
   - `ERROR`: "Ошибка при запросе к LLM: {error}"
   - `ERROR`: "Ошибка при обработке сообщения: {error}" (с traceback)

### Принцип

- Минимальное логирование для отладки
- Фокус на ошибках и ключевых событиях
- Без избыточного логирования каждого шага

