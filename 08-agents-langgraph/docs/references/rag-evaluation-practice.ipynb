{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ RAG —Å–∏—Å—Ç–µ–º\n",
        "\n",
        "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∑–∞–Ω—è—Ç–∏–µ –ø–æ –æ—Ü–µ–Ω–∫–µ –∫–∞—á–µ—Å—Ç–≤–∞ RAG —Å–∏—Å—Ç–µ–º —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RAGAS –∏ LangSmith"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU langchain langchain-openai langchain-community langchain-core langchain-text-splitters\n",
        "%pip install -qU pypdf python-dotenv\n",
        "%pip install -qU langsmith ragas datasets sentence-transformers pandas\n",
        "%pip install matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
        "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\"\n",
        "assert os.getenv(\"LANGSMITH_API_KEY\"), \"LANGSMITH_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\"\n",
        "\n",
        "print(\"‚úì –û–∫—Ä—É–∂–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from typing import List, Dict, Any\n",
        "import json\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import InMemoryVectorStore\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "from langsmith import Client\n",
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    Faithfulness,\n",
        "    AnswerRelevancy,\n",
        "    AnswerCorrectness,\n",
        "    AnswerSimilarity,\n",
        "    ContextRecall,\n",
        "    ContextPrecision,\n",
        ")\n",
        "# –ò—Å–ø–æ–ª—å–∑—É–µ–º LangChain –æ–±–µ—Ä—Ç–∫–∏ (—Ä–∞–±–æ—Ç–∞—é—Ç, —Ö–æ—Ç—è –∏ deprecated)\n",
        "# –ù–æ–≤—ã–µ –º–µ—Ç–æ–¥—ã –≤—ã–∑—ã–≤–∞—é—Ç –æ—à–∏–±–∫–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å instructor\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from datasets import Dataset\n",
        "\n",
        "print(\"‚úì –í—Å–µ –∏–º–ø–æ—Ä—Ç—ã —É—Å–ø–µ—à–Ω—ã\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö RAG –ø–∞–π–ø–ª–∞–π–Ω–æ–≤\n",
        "\n",
        "–°–æ–∑–¥–∞–¥–∏–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ RAG –ø–∞–π–ø–ª–∞–π–Ω–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_pdf_documents(data_dir: str) -> List:\n",
        "    \"\"\"–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö PDF –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\"\"\"\n",
        "    pages = []\n",
        "    data_path = Path(data_dir)\n",
        "    \n",
        "    if not data_path.exists():\n",
        "        raise FileNotFoundError(f\"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {data_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞\")\n",
        "    \n",
        "    pdf_files = list(data_path.glob(\"*.pdf\"))\n",
        "    print(f\"–ù–∞–π–¥–µ–Ω–æ {len(pdf_files)} PDF —Ñ–∞–π–ª–æ–≤ –≤ {data_dir}\")\n",
        "    \n",
        "    for pdf_file in pdf_files:\n",
        "        loader = PyPDFLoader(str(pdf_file))\n",
        "        pages.extend(loader.load())\n",
        "        print(f\"  –ó–∞–≥—Ä—É–∂–µ–Ω: {pdf_file.name}\")\n",
        "    \n",
        "    return pages\n",
        "\n",
        "def split_documents(pages: List, chunk_size: int = 500, chunk_overlap: int = 50) -> List:\n",
        "    \"\"\"–†–∞–∑–±–∏–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ —á–∞–Ω–∫–∏\"\"\"\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    )\n",
        "    chunks = text_splitter.split_documents(pages)\n",
        "    print(f\"–°–æ–∑–¥–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤\")\n",
        "    return chunks\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã\n",
        "# –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ notebook\n",
        "data_dir = \"documents\"\n",
        "pages = load_pdf_documents(data_dir)\n",
        "chunks = split_documents(pages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 –°–æ–∑–¥–∞–Ω–∏–µ RAG –ø–∞–π–ø–ª–∞–π–Ω–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_rag_pipeline(\n",
        "    chunks: List,\n",
        "    embedding_model: str,\n",
        "    llm_model: str,\n",
        "    k: int = 3,\n",
        "    temperature: float = 0.0\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    –°–æ–∑–¥–∞–Ω–∏–µ RAG –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏\n",
        "    \n",
        "    Args:\n",
        "        chunks: —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏\n",
        "        embedding_model: –º–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
        "        llm_model: —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤\n",
        "        k: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è retrieval\n",
        "        temperature: —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è LLM (0.0 = –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, 1.0+ = –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π)\n",
        "    \n",
        "    Returns:\n",
        "        dict —Å –∫–ª—é—á–∞–º–∏: retriever, rag_chain, config\n",
        "        \n",
        "        rag_chain –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å –∫–ª—é—á–∞–º–∏:\n",
        "        - answer: —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç\n",
        "        - documents: —Å–ø–∏—Å–æ–∫ Document –æ–±—ä–µ–∫—Ç–æ–≤ –∏–∑ retriever\n",
        "    \"\"\"\n",
        "    # –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞\n",
        "    embeddings = OpenAIEmbeddings(model=embedding_model)\n",
        "    vector_store = InMemoryVectorStore.from_documents(\n",
        "        documents=chunks,\n",
        "        embedding=embeddings\n",
        "    )\n",
        "    \n",
        "    # –°–æ–∑–¥–∞–Ω–∏–µ retriever\n",
        "    retriever = vector_store.as_retriever(search_kwargs={\"k\": k})\n",
        "    \n",
        "    # –ü—Ä–æ–º–ø—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞\n",
        "    SYSTEM_TEMPLATE = \"\"\"\n",
        "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.\n",
        "–ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–∞.\n",
        "–ï—Å–ª–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ, —Å–∫–∞–∂–∏ \"–Ø –Ω–µ –Ω–∞—à–µ–ª –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å –≤ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö\".\n",
        "–ë—É–¥—å –∫—Ä–∞—Ç–∫–∏–º –∏ —Ç–æ—á–Ω—ã–º.\n",
        "\n",
        "–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n",
        "{context}\n",
        "    \"\"\"\n",
        "    \n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", SYSTEM_TEMPLATE),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ])\n",
        "    \n",
        "    # LLM\n",
        "    llm = ChatOpenAI(model=llm_model, temperature=temperature)\n",
        "    \n",
        "    # RAG —Ü–µ–ø–æ—á–∫–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
        "    # RAG —Ü–µ–ø–æ—á–∫–∞ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ —Ç—Ä–µ—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —à–∞–≥–æ–≤, —Å–æ–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º |\n",
        "    rag_chain = (\n",
        "        # –®–∞–≥ 1: –ü–æ–ª—É—á–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ retriever\n",
        "        # RunnablePassthrough.assign() –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤–æ–µ –ø–æ–ª–µ \"documents\" –∫ –≤—Ö–æ–¥–Ω–æ–º—É —Å–ª–æ–≤–∞—Ä—é\n",
        "        # –ü—Ä–∏ —ç—Ç–æ–º –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, \"question\") —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è\n",
        "        # lambda x: retriever.invoke(x[\"question\"]) - –±–µ—Ä–µ—Ç –≤–æ–ø—Ä–æ—Å –∏–∑ –≤—Ö–æ–¥–∞ –∏ –∏—â–µ—Ç –ø–æ—Ö–æ–∂–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã\n",
        "        RunnablePassthrough.assign(\n",
        "            documents=lambda x: retriever.invoke(x[\"question\"]),\n",
        "        )\n",
        "        # –®–∞–≥ 2: –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
        "        # –°–Ω–æ–≤–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º RunnablePassthrough.assign() –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø–æ–ª—è \"answer\"\n",
        "        # –¢–µ–ø–µ—Ä—å –≤ x —É–∂–µ –µ—Å—Ç—å –∏ \"question\", –∏ \"documents\" –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —à–∞–≥–∞\n",
        "        | RunnablePassthrough.assign(\n",
        "            # –í–Ω—É—Ç—Ä–∏ lambda —Å–æ–∑–¥–∞–µ–º –ø–æ–¥—Ü–µ–ø–æ—á–∫—É: prompt | llm | StrOutputParser()\n",
        "            # 1. –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç: –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ \\n\\n\n",
        "            # 2. –ü–µ—Ä–µ–¥–∞–µ–º –≤ prompt –≤–æ–ø—Ä–æ—Å –∏ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç\n",
        "            # 3. LLM –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–º–ø—Ç–∞\n",
        "            # 4. StrOutputParser() –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –∏–∑ –æ–±—ä–µ–∫—Ç–∞ LLM\n",
        "            answer=lambda x: (prompt | llm | StrOutputParser()).invoke({\n",
        "                \"context\": \"\\n\\n\".join(doc.page_content for doc in x[\"documents\"]),\n",
        "                \"question\": x[\"question\"]\n",
        "            })\n",
        "        )\n",
        "        # –®–∞–≥ 3: –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
        "        # lambda x: {...} - –±–µ—Ä–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å–æ –≤—Å–µ–º–∏ –ø–æ–ª—è–º–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ\n",
        "        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ \"answer\" (—Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞) –∏ \"documents\" (—Å–ø–∏—Å–æ–∫ Document –æ–±—ä–µ–∫—Ç–æ–≤)\n",
        "        # –≠—Ç–æ —É–ø—Ä–æ—â–∞–µ—Ç —Ä–∞–±–æ—Ç—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –∏ –¥–µ–ª–∞–µ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —á–∏—â–µ\n",
        "        | (lambda x: {\"answer\": x[\"answer\"], \"documents\": x[\"documents\"]})\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        \"retriever\": retriever,  # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º retriever –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤\n",
        "        \"rag_chain\": rag_chain,\n",
        "        \"config\": {\n",
        "            \"embedding_model\": embedding_model,\n",
        "            \"llm_model\": llm_model,\n",
        "            \"k\": k,\n",
        "            \"temperature\": temperature\n",
        "        }\n",
        "    }\n",
        "\n",
        "print(\"‚úì –§—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞ –≥–æ—Ç–æ–≤–∞ (answer –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π output)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 –°–æ–∑–¥–∞–Ω–∏–µ –¥–≤—É—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü–∞–π–ø–ª–∞–π–Ω 1: –ë–æ–ª–µ–µ —Å–ª–∞–±–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è\n",
        "pipeline_1 = create_rag_pipeline(\n",
        "    chunks=chunks,\n",
        "    embedding_model=\"text-embedding-ada-002\",  # –°—Ç–∞—Ä–∞—è –º–æ–¥–µ–ª—å\n",
        "    llm_model=\"gpt-3.5-turbo\",  # –ë–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å\n",
        "    k=1,  # –¢–æ–ª—å–∫–æ 1 –¥–æ–∫—É–º–µ–Ω—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ (–º–∏–Ω–∏–º—É–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏)\n",
        "    temperature=2.0  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å (–æ—á–µ–Ω—å –Ω–µ–ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–π)\n",
        ")\n",
        "print(f\"‚úì –ü–∞–π–ø–ª–∞–π–Ω 1 —Å–æ–∑–¥–∞–Ω: {pipeline_1['config']}\")\n",
        "\n",
        "# –ü–∞–π–ø–ª–∞–π–Ω 2: –ë–æ–ª–µ–µ —Å–∏–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è\n",
        "pipeline_2 = create_rag_pipeline(\n",
        "    chunks=chunks,\n",
        "    embedding_model=\"text-embedding-3-large\",  # –ù–æ–≤–∞—è –º–æ–¥–µ–ª—å\n",
        "    llm_model=\"gpt-4.1\",  # –ë–æ–ª–µ–µ –º–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å\n",
        "    k=3,\n",
        "    temperature=0.0  # –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å)\n",
        ")\n",
        "print(f\"‚úì –ü–∞–π–ø–ª–∞–π–Ω 2 —Å–æ–∑–¥–∞–Ω: {pipeline_2['config']}\")\n",
        "\n",
        "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞–π–ø–ª–∞–π–Ω—ã –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞\n",
        "pipelines = {\n",
        "    \"pipeline_1_weak\": pipeline_1,\n",
        "    \"pipeline_2_strong\": pipeline_2\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4 –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –¢–µ—Å—Ç–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å\n",
        "test_question = \"–ê —á—Ç–æ –Ω—É–∂–Ω–æ –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è –≤–∫–ª–∞–¥–∞ –æ–Ω–ª–∞–π–Ω?\"\n",
        "\n",
        "print(f\"–í–æ–ø—Ä–æ—Å: {test_question}\\n\")\n",
        "\n",
        "for name, pipeline in pipelines.items():\n",
        "    print(f\"--- {name} ---\")\n",
        "    result = pipeline[\"rag_chain\"].invoke({\"question\": test_question})\n",
        "    print(f\"–û—Ç–≤–µ—Ç: {result['answer'][:200]}...\")\n",
        "    print(f\"–ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {len(result['documents'])}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.5 –¢—Ä–µ–π—Å–∏–Ω–≥ –≤ LangSmith\n",
        "\n",
        "–ë–ª–∞–≥–æ–¥–∞—Ä—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º –æ–∫—Ä—É–∂–µ–Ω–∏—è, **–≤—Å–µ –Ω–∞—à–∏ –≤—ã–∑–æ–≤—ã –∫ LangChain –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ª–æ–≥–∏—Ä—É—é—Ç—Å—è –≤ LangSmith**.\n",
        "\n",
        "**–ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –≤ `.env` —Ñ–∞–π–ª–µ:**\n",
        "```bash\n",
        "LANGSMITH_API_KEY=lsv2_pt_...           # API –∫–ª—é—á –∏–∑ LangSmith\n",
        "LANGSMITH_TRACING_V2=true               # –í–∫–ª—é—á–∏—Ç—å —Ç—Ä–µ–π—Å–∏–Ω–≥\n",
        "LANGSMITH_PROJECT=my-rag-project        # –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
        "```\n",
        "\n",
        "**–ß—Ç–æ –¥–∞—ë—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ç—Ä–µ–π—Å–∏–Ω–≥:**\n",
        "- üîç –ü—Ä–æ—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–π—Å—ã –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –≤ LangSmith UI\n",
        "- üìä –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å latency, token usage, –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —à–∞–≥–∏\n",
        "- üêõ –û—Ç–ª–∞–∂–∏–≤–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—ã –≤ RAG –ø–∞–π–ø–ª–∞–π–Ω–∞—Ö\n",
        "- üìà –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏\n",
        "- üí∞ –û—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å —Å—Ç–æ–∏–º–æ—Å—Ç—å API –≤—ã–∑–æ–≤–æ–≤\n",
        "\n",
        "**–ü—Ä–∏–º–µ—Ä —Ç—Ä–µ–π—Å–∞ RAG –ø–∞–π–ø–ª–∞–π–Ω–∞ –≤ LangSmith UI:**\n",
        "\n",
        "![LangSmith Trace](./langsmith_trace.png)\n",
        "\n",
        "–ù–∞ —Å–∫—Ä–∏–Ω—à–æ—Ç–µ –≤–∏–¥–Ω–æ –¥–µ—Ç–∞–ª—å–Ω—ã–π —Ç—Ä–µ–π—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è RAG –ø–∞–π–ø–ª–∞–π–Ω–∞:\n",
        "\n",
        "**–õ–µ–≤–∞—è –ø–∞–Ω–µ–ª—å (TRACE) - —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:**\n",
        "- `RunnableSequence` - –≥–ª–∞–≤–Ω–∞—è —Ü–µ–ø–æ—á–∫–∞ (5.03s, 603 tokens)\n",
        "- `RunnableAssign<documents>` - —ç—Ç–∞–ø retrieval —Å VectorStoreRetriever (0.56s)\n",
        "- `RunnableAssign<answer>` - —ç—Ç–∞–ø –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ (4.48s)\n",
        "  - `ChatPromptTemplate` - —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ (0.00s)\n",
        "  - `ChatOpenAI` (gpt-4.1) - –≤—ã–∑–æ–≤ LLM (4.47s, 603 tokens)\n",
        "  - `StrOutputParser` - –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ (0.00s)\n",
        "\n",
        "**–ü—Ä–∞–≤–∞—è –ø–∞–Ω–µ–ª—å - –¥–µ—Ç–∞–ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:**\n",
        "- **Input** - –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
        "- **Output** - —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å `documents` (3 retrieved –¥–æ–∫—É–º–µ–Ω—Ç–∞) –∏ `answer`\n",
        "- **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞**: 603 tokens / $0.002106, Latency: 5.03s\n",
        "- **Metadata** - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞–π–ø–ª–∞–π–Ω–µ\n",
        "\n",
        "–≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –≤–∏–¥–µ—Ç—å –∫–∞–∂–¥—ã–π —à–∞–≥ RAG –ø–∞–π–ø–ª–∞–π–Ω–∞, –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è, —Å—Ç–æ–∏–º–æ—Å—Ç—å –∏ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏\n",
        "\n",
        "–°–æ–∑–¥–∞–¥–∏–º ground truth –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 –°–∏–Ω—Ç–µ–∑ –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def synthesize_qa_pairs_from_chunks(\n",
        "    chunks: List,\n",
        "    llm_model: str = \"gpt-4.1\",\n",
        "    num_questions_per_chunk: int = 1\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    –°–∏–Ω—Ç–µ–∑ –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–∞–Ω–∫–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
        "    \n",
        "    Returns:\n",
        "        List of dicts with keys: question, ground_truth, contexts\n",
        "    \"\"\"\n",
        "    llm = ChatOpenAI(model=llm_model, temperature=0.7)\n",
        "    \n",
        "    synthesis_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"\n",
        "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –≤–æ–ø—Ä–æ—Å–Ω–æ-–æ—Ç–≤–µ—Ç–Ω—ã—Ö –ø–∞—Ä –¥–ª—è –æ—Ü–µ–Ω–∫–∏ RAG —Å–∏—Å—Ç–µ–º.\n",
        "–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å–æ–∑–¥–∞–π {num_questions} —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤,\n",
        "–Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –æ—Ç–≤–µ—Ç–∏—Ç—å –∏—Å–ø–æ–ª—å–∑—É—è —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç.\n",
        "\n",
        "–í–æ–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å:\n",
        "- –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏ (—Ç–∞–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã –º–æ–≥—É—Ç –∑–∞–¥–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏)\n",
        "- –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–º–∏ (—Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã: —Ñ–∞–∫—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ, —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–µ, —É—Ç–æ—á–Ω—è—é—â–∏–µ)\n",
        "- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ (–º–æ–∂–Ω–æ –¥–∞—Ç—å —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞)\n",
        "\n",
        "–î–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ —Ç–∞–∫–∂–µ —Å–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–∏–π —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞.\n",
        "\n",
        "–í–ê–ñ–ù–û: –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞:\n",
        "{{\n",
        "  \"qa_pairs\": [\n",
        "    {{\"question\": \"...\", \"answer\": \"...\"}},\n",
        "    ...\n",
        "  ]\n",
        "}}\n",
        "        \"\"\"),\n",
        "        (\"human\", \"–¢–µ–∫—Å—Ç:\\n{chunk_text}\")\n",
        "    ])\n",
        "    \n",
        "    qa_pairs = []\n",
        "    \n",
        "    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —á–∞–Ω–∫\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        if len(chunk.page_content.strip()) < 100:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —á–∞–Ω–∫–∏\n",
        "            continue\n",
        "            \n",
        "        try:\n",
        "            response = llm.invoke(\n",
        "                synthesis_prompt.format_messages(\n",
        "                    num_questions=num_questions_per_chunk,\n",
        "                    chunk_text=chunk.page_content[:2000]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É\n",
        "                )\n",
        "            )\n",
        "            \n",
        "            # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç\n",
        "            content = response.content.strip()\n",
        "            \n",
        "            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±–µ—Ä–Ω—É—Ç –≤ markdown)\n",
        "            if \"```json\" in content:\n",
        "                content = content.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "            elif \"```\" in content:\n",
        "                # –ü—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∏–∑ –ª—é–±–æ–≥–æ code block\n",
        "                parts = content.split(\"```\")\n",
        "                if len(parts) >= 2:\n",
        "                    content = parts[1].strip()\n",
        "                    if content.startswith(\"json\"):\n",
        "                        content = content[4:].strip()\n",
        "            \n",
        "            # –£–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã/—Å—É—Ñ—Ñ–∏–∫—Å—ã\n",
        "            content = content.strip()\n",
        "            if not content.startswith(\"{\"):\n",
        "                # –ò—â–µ–º –ø–µ—Ä–≤—É—é –æ—Ç–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É\n",
        "                idx = content.find(\"{\")\n",
        "                if idx >= 0:\n",
        "                    content = content[idx:]\n",
        "            \n",
        "            data = json.loads(content)\n",
        "            \n",
        "            for qa in data.get(\"qa_pairs\", []):\n",
        "                if \"question\" in qa and \"answer\" in qa:\n",
        "                    qa_pairs.append({\n",
        "                        \"question\": qa[\"question\"],\n",
        "                        \"ground_truth\": qa[\"answer\"],\n",
        "                        \"contexts\": [chunk.page_content],  # –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç\n",
        "                        \"metadata\": {\n",
        "                            \"source\": chunk.metadata.get(\"source\", \"unknown\"),\n",
        "                            \"page\": chunk.metadata.get(\"page\", -1)\n",
        "                        }\n",
        "                    })\n",
        "            \n",
        "            if (i + 1) % 10 == 0:\n",
        "                print(f\"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i + 1}/{len(chunks)} —á–∞–Ω–∫–æ–≤, —Å–æ–∑–¥–∞–Ω–æ {len(qa_pairs)} QA –ø–∞—Ä\")\n",
        "                \n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –¥–ª—è —á–∞–Ω–∫–∞ {i}: {e}\")\n",
        "            print(f\"–û—Ç–≤–µ—Ç LLM: {content[:200]}...\")\n",
        "            continue\n",
        "        except Exception as e:\n",
        "            print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —á–∞–Ω–∫–∞ {i}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    print(f\"\\n–í—Å–µ–≥–æ —Å–æ–∑–¥–∞–Ω–æ {len(qa_pairs)} QA –ø–∞—Ä\")\n",
        "    return qa_pairs\n",
        "\n",
        "print(\"‚úì –§—É–Ω–∫—Ü–∏—è —Å–∏–Ω—Ç–µ–∑–∞ QA –ø–∞—Ä –≥–æ—Ç–æ–≤–∞\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç (–¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤)\n",
        "# –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –º–æ–∂–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ —á–∞–Ω–∫–∏\n",
        "# –†–∞–∑–¥–µ–ª–∏–º –≤—Å–µ —á–∞–Ω–∫–∏ –Ω–∞ –≥—Ä—É–ø–ø—ã –∏ –≤–æ–∑—å–º–µ–º –ø–æ –æ–¥–Ω–æ–º—É —á–∞–Ω–∫—É –∏–∑ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã\n",
        "num_samples = 4  # –¢—Ä–µ–±—É–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤\n",
        "group_size = len(chunks) // num_samples\n",
        "sample_chunks = [chunks[i * group_size] for i in range(num_samples)]\n",
        "\n",
        "qa_dataset = synthesize_qa_pairs_from_chunks(\n",
        "    chunks=sample_chunks\n",
        ")\n",
        "\n",
        "print(f\"\\n–°–æ–∑–¥–∞–Ω–æ {len(qa_dataset)} –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ\")\n",
        "if qa_dataset:\n",
        "    print(f\"\\n–ü—Ä–∏–º–µ—Ä –ø–µ—Ä–≤–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞:\")\n",
        "    print(json.dumps(qa_dataset[0], ensure_ascii=False, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. RAGAS. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ RAG –ø–∞–π–ø–ª–∞–π–Ω–æ–≤\n",
        "\n",
        "–û—Ü–µ–Ω–∏–º –∫–∞—á–µ—Å—Ç–≤–æ –∫–∞–∂–¥–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å –ø–æ–º–æ—â—å—é RAGAS –º–µ—Ç—Ä–∏–∫."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 –§—É–Ω–∫—Ü–∏—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_rag_pipeline(\n",
        "    pipeline: Dict[str, Any],\n",
        "    qa_pairs: List[Dict[str, Any]],\n",
        "    pipeline_name: str\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ RAG –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å –ø–æ–º–æ—â—å—é RAGAS\n",
        "    \n",
        "    Returns:\n",
        "        dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ—Ü–µ–Ω–∫–∏\n",
        "    \"\"\"\n",
        "    print(f\"\\n–û—Ü–µ–Ω–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞: {pipeline_name}\")\n",
        "    \n",
        "    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç—ã –æ—Ç –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–ª—è –≤—Å–µ—Ö –≤–æ–ø—Ä–æ—Å–æ–≤\n",
        "    questions = []\n",
        "    answers = []\n",
        "    ground_truths = []\n",
        "    contexts_list = []\n",
        "    \n",
        "    for qa in qa_pairs:\n",
        "        question = qa[\"question\"]\n",
        "        \n",
        "        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã –æ—Ç –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–¥–Ω–∏–º –≤—ã–∑–æ–≤–æ–º\n",
        "        result = pipeline[\"rag_chain\"].invoke({\"question\": question})\n",
        "        answer = result[\"answer\"]\n",
        "        retrieved_chunks = result[\"documents\"]\n",
        "        contexts = [chunk.page_content for chunk in retrieved_chunks]\n",
        "        \n",
        "        questions.append(question)\n",
        "        answers.append(answer)\n",
        "        ground_truths.append(qa[\"ground_truth\"])\n",
        "        contexts_list.append(contexts)\n",
        "    \n",
        "    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è RAGAS\n",
        "    ragas_dataset = Dataset.from_dict({\n",
        "        \"question\": questions,\n",
        "        \"answer\": answers,\n",
        "        \"ground_truth\": ground_truths,\n",
        "        \"contexts\": contexts_list\n",
        "    })\n",
        "    \n",
        "    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è RAGAS –æ—Ü–µ–Ω–∫–∏ (–Ω–µ –∏–∑ –ø–∞–π–ø–ª–∞–π–Ω–∞)\n",
        "    # –≠—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–Ω—É—é –æ—Ü–µ–Ω–∫—É –≤—Å–µ—Ö –ø–∞–π–ø–ª–∞–π–Ω–æ–≤\n",
        "    ragas_llm_model = \"gpt-4.1\"\n",
        "    ragas_embedding_model = \"text-embedding-3-large\"\n",
        "    \n",
        "    # –°–æ–∑–¥–∞–µ–º LangChain LLM –∏ embeddings –¥–ª—è RAGAS\n",
        "    langchain_llm = ChatOpenAI(model=ragas_llm_model, temperature=0.0, n=1)\n",
        "    langchain_embeddings = OpenAIEmbeddings(model=ragas_embedding_model)\n",
        "    \n",
        "    # –û–±–µ—Ä—Ç—ã–≤–∞–µ–º –¥–ª—è RAGAS (deprecated, –Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ)\n",
        "    # –ù–æ–≤—ã–µ –º–µ—Ç–æ–¥—ã (llm_factory, OpenAIEmbeddings –∏–∑ ragas) –≤—ã–∑—ã–≤–∞—é—Ç –æ—à–∏–±–∫–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏\n",
        "    ragas_llm = LangchainLLMWrapper(langchain_llm)\n",
        "    ragas_embeddings = LangchainEmbeddingsWrapper(langchain_embeddings)\n",
        "    \n",
        "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
        "    # faithfulness, context_recall, context_precision: —Ç–æ–ª—å–∫–æ llm\n",
        "    # answer_similarity: —Ç–æ–ª—å–∫–æ embeddings\n",
        "    # answer_relevancy, answer_correctness: –∏ llm, –∏ embeddings\n",
        "    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º strictness=1 –¥–ª—è –º–µ—Ç—Ä–∏–∫, –∫–æ—Ç–æ—Ä—ã–µ —Ç—Ä–µ–±—É—é—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–π\n",
        "    # –≠—Ç–æ —É–º–µ–Ω—å—à–∏—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤, –Ω–æ –º–æ–∂–µ—Ç –Ω–µ–º–Ω–æ–≥–æ —Å–Ω–∏–∑–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å –æ—Ü–µ–Ω–∫–∏\n",
        "    answer_similarity_metric = AnswerSimilarity(embeddings=ragas_embeddings)\n",
        "    \n",
        "    metrics = [\n",
        "        Faithfulness(llm=ragas_llm),\n",
        "        AnswerRelevancy(llm=ragas_llm, embeddings=ragas_embeddings, strictness=1),  # –£–º–µ–Ω—å—à–∞–µ–º –¥–æ 1 –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n",
        "        AnswerCorrectness(\n",
        "            llm=ragas_llm,\n",
        "            embeddings=ragas_embeddings,\n",
        "            answer_similarity=answer_similarity_metric\n",
        "        ),\n",
        "        answer_similarity_metric,\n",
        "        ContextRecall(llm=ragas_llm),\n",
        "        ContextPrecision(llm=ragas_llm),\n",
        "    ]\n",
        "    \n",
        "    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ —Å —è–≤–Ω–æ–π –ø–µ—Ä–µ–¥–∞—á–µ–π llm –∏ embeddings\n",
        "    # –î–æ–±–∞–≤–ª—è–µ–º RunConfig –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è (–∫–∞–∫ –≤ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–µ)\n",
        "    from ragas.run_config import RunConfig\n",
        "    \n",
        "    run_config = RunConfig(\n",
        "        max_workers=1,  # –£–º–µ–Ω—å—à–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏\n",
        "        timeout=360,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –¥–æ 6 –º–∏–Ω—É—Ç\n",
        "        max_retries=20,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫\n",
        "        max_wait=120,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏\n",
        "        log_tenacity=True  # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ø—ã—Ç–∫–∏ retry\n",
        "    )\n",
        "    \n",
        "    result = evaluate(\n",
        "        ragas_dataset,\n",
        "        metrics=metrics,\n",
        "        llm=ragas_llm,\n",
        "        embeddings=ragas_embeddings,\n",
        "        run_config=run_config,  # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è retry\n",
        "    )\n",
        "    \n",
        "    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (RAGAS –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ EvaluationResult)\n",
        "    metrics_dict = {}\n",
        "    for metric_name in [\"faithfulness\", \"answer_relevancy\", \"answer_correctness\", \n",
        "                       \"answer_similarity\", \"context_recall\", \"context_precision\"]:\n",
        "        try:\n",
        "            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏\n",
        "            scores = None\n",
        "            if hasattr(result, metric_name):\n",
        "                scores = getattr(result, metric_name)\n",
        "            elif hasattr(result, '_scores_dict') and metric_name in result._scores_dict:\n",
        "                scores = result._scores_dict[metric_name]\n",
        "            elif isinstance(result, dict) and metric_name in result:\n",
        "                scores = result[metric_name]\n",
        "            else:\n",
        "                # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —á–µ—Ä–µ–∑ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é (–µ—Å–ª–∏ —ç—Ç–æ Dataset –∏–ª–∏ dict-like)\n",
        "                try:\n",
        "                    scores = result[metric_name]\n",
        "                except (KeyError, TypeError, AttributeError):\n",
        "                    continue\n",
        "            \n",
        "            if scores is not None:\n",
        "                if isinstance(scores, list):\n",
        "                    avg_score = sum(scores) / len(scores) if scores else 0\n",
        "                else:\n",
        "                    avg_score = float(scores) if scores is not None else 0\n",
        "                metrics_dict[metric_name] = {\n",
        "                    \"scores\": scores if isinstance(scores, list) else [scores],\n",
        "                    \"average\": avg_score\n",
        "                }\n",
        "        except (KeyError, AttributeError, TypeError) as e:\n",
        "            print(f\"  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –º–µ—Ç—Ä–∏–∫—É {metric_name}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    print(f\"\\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ –¥–ª—è {pipeline_name}:\")\n",
        "    for metric_name, values in metrics_dict.items():\n",
        "        if isinstance(values, dict) and \"average\" in values:\n",
        "            print(f\"  {metric_name}: {values['average']:.3f}\")\n",
        "    \n",
        "    return {\n",
        "        \"pipeline_name\": pipeline_name,\n",
        "        \"metrics\": metrics_dict,\n",
        "        \"config\": pipeline[\"config\"],\n",
        "        \"ragas_result\": result  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞\n",
        "    }\n",
        "\n",
        "print(\"‚úì –§—É–Ω–∫—Ü–∏—è –æ—Ü–µ–Ω–∫–∏ –≥–æ—Ç–æ–≤–∞\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 –û—Ü–µ–Ω–∫–∞ –≤—Å–µ—Ö –ø–∞–π–ø–ª–∞–π–Ω–æ–≤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation_results = {}\n",
        "\n",
        "for name, pipeline in pipelines.items():\n",
        "    results = evaluate_rag_pipeline(\n",
        "        pipeline=pipeline,\n",
        "        qa_pairs=qa_dataset,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç\n",
        "        pipeline_name=name\n",
        "    )\n",
        "    evaluation_results[name] = results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
        "comparison_data = []\n",
        "\n",
        "for name, results in evaluation_results.items():\n",
        "    metrics = results[\"metrics\"]\n",
        "    row = {\"Pipeline\": name}\n",
        "    \n",
        "    for metric_name, values in metrics.items():\n",
        "        if isinstance(values, dict) and \"average\" in values:\n",
        "            row[metric_name] = values['average']\n",
        "    \n",
        "    comparison_data.append(row)\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison_data)\n",
        "\n",
        "# –í—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—É\n",
        "print(\"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤:\")\n",
        "df_display = df_comparison.copy()\n",
        "for col in df_display.columns:\n",
        "    if col != \"Pipeline\":\n",
        "        df_display[col] = df_display[col].apply(lambda x: f\"{x:.3f}\" if isinstance(x, (int, float)) else x)\n",
        "print(df_display.to_string(index=False))\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "metric_columns = [col for col in df_comparison.columns if col != \"Pipeline\"]\n",
        "\n",
        "if metric_columns:\n",
        "    # –ì—Ä–∞—Ñ–∏–∫ 1: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫ –¥–ª—è –≤—Å–µ—Ö –ø–∞–π–ø–ª–∞–π–Ω–æ–≤\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    \n",
        "    # –ë–∞—Ä–ø–ª–æ—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫\n",
        "    x = np.arange(len(df_comparison))\n",
        "    width = 0.8 / len(metric_columns)\n",
        "    \n",
        "    for i, metric in enumerate(metric_columns):\n",
        "        offset = width * i - (width * len(metric_columns) / 2 - width / 2)\n",
        "        axes[0].bar(x + offset, df_comparison[metric], width, label=metric, alpha=0.8)\n",
        "    \n",
        "    axes[0].set_xlabel('Pipeline', fontsize=12)\n",
        "    axes[0].set_ylabel('Score', fontsize=12)\n",
        "    axes[0].set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø–æ –ø–∞–π–ø–ª–∞–π–Ω–∞–º', fontsize=14, fontweight='bold')\n",
        "    axes[0].set_xticks(x)\n",
        "    axes[0].set_xticklabels(df_comparison['Pipeline'], rotation=45, ha='right')\n",
        "    axes[0].legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "    axes[0].set_ylim(0, 1.0)\n",
        "    \n",
        "    # –†–∞–¥–∞—Ä–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø–∞–π–ø–ª–∞–π–Ω–æ–≤\n",
        "    angles = np.linspace(0, 2 * np.pi, len(metric_columns), endpoint=False).tolist()\n",
        "    angles += angles[:1]\n",
        "    \n",
        "    ax = plt.subplot(122, projection='polar')\n",
        "    \n",
        "    for idx, row in df_comparison.iterrows():\n",
        "        values = [row[metric] for metric in metric_columns]\n",
        "        values += values[:1]\n",
        "        ax.plot(angles, values, 'o-', linewidth=2, label=row['Pipeline'])\n",
        "        ax.fill(angles, values, alpha=0.15)\n",
        "    \n",
        "    ax.set_xticks(angles[:-1])\n",
        "    ax.set_xticklabels(metric_columns, size=10)\n",
        "    ax.set_ylim(0, 1.0)\n",
        "    ax.set_title('–†–∞–¥–∞—Ä–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ –º–µ—Ç—Ä–∏–∫', fontsize=14, fontweight='bold', pad=20)\n",
        "    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
        "    ax.grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # –ì—Ä–∞—Ñ–∏–∫ 2: –î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –∫–∞–∂–¥–æ–π –º–µ—Ç—Ä–∏–∫–µ\n",
        "    n_metrics = len(metric_columns)\n",
        "    fig, axes = plt.subplots(1, n_metrics, figsize=(5 * n_metrics, 5))\n",
        "    \n",
        "    if n_metrics == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for idx, metric in enumerate(metric_columns):\n",
        "        axes[idx].barh(df_comparison['Pipeline'], df_comparison[metric], color=plt.cm.viridis(np.linspace(0, 1, len(df_comparison))))\n",
        "        axes[idx].set_xlabel('Score', fontsize=11)\n",
        "        axes[idx].set_title(metric, fontsize=12, fontweight='bold')\n",
        "        axes[idx].set_xlim(0, 1.0)\n",
        "        axes[idx].grid(axis='x', alpha=0.3)\n",
        "        \n",
        "        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ\n",
        "        for i, v in enumerate(df_comparison[metric]):\n",
        "            axes[idx].text(v + 0.02, i, f'{v:.3f}', va='center', fontsize=10)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ–º —Å LangSmith\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ LangSmith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def upload_dataset_to_langsmith(\n",
        "    qa_pairs: List[Dict[str, Any]],\n",
        "    dataset_name: str,\n",
        "    description: str = \"RAG evaluation dataset\"\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤ –≤ LangSmith\n",
        "    \n",
        "    Args:\n",
        "        qa_pairs: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∫–ª—é—á–∞–º–∏ 'question', 'ground_truth', 'contexts', 'metadata'\n",
        "        dataset_name: –ò–º—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ LangSmith\n",
        "        description: –û–ø–∏—Å–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
        "    \n",
        "    Returns:\n",
        "        ID —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
        "    \"\"\"\n",
        "    client = Client()\n",
        "    \n",
        "    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –Ω–∞—à —Ñ–æ—Ä–º–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç LangSmith\n",
        "    examples = []\n",
        "    for qa in qa_pairs:\n",
        "        example = {\n",
        "            \"inputs\": {\"question\": qa[\"question\"]},\n",
        "            \"outputs\": {\"answer\": qa[\"ground_truth\"]},\n",
        "            \"metadata\": {\n",
        "                **qa.get(\"metadata\", {}),\n",
        "                \"contexts\": qa.get(\"contexts\", [])\n",
        "            }\n",
        "        }\n",
        "        examples.append(example)\n",
        "    \n",
        "    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç\n",
        "    dataset = client.create_dataset(\n",
        "        dataset_name=dataset_name,\n",
        "        description=description\n",
        "    )\n",
        "    \n",
        "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã\n",
        "    client.create_examples(\n",
        "        dataset_id=dataset.id,\n",
        "        examples=examples\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úì –î–∞—Ç–∞—Å–µ—Ç '{dataset_name}' —Å–æ–∑–¥–∞–Ω –≤ LangSmith\")\n",
        "    print(f\"  ID –¥–∞—Ç–∞—Å–µ—Ç–∞: {dataset.id}\")\n",
        "    print(f\"  –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {len(examples)}\")\n",
        "    \n",
        "    return dataset.id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—à –¥–∞—Ç–∞—Å–µ—Ç –≤ LangSmith\n",
        "DATASET_NAME = \"SBERAGENTS_RAG_EVALUATION_DATASET_V1\"\n",
        "dataset_id = upload_dataset_to_langsmith(\n",
        "    qa_pairs=qa_dataset,\n",
        "    dataset_name=DATASET_NAME,\n",
        "    description=\"–í–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ RAG —Å–∏—Å—Ç–µ–º\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 –ü—Ä–æ—Å–º–æ—Ç—Ä —Å–ø–∏—Å–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°–ø–æ—Å–æ–± 1: –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –¥–∞—Ç–∞—Å–µ—Ç—ã\n",
        "client = Client()\n",
        "datasets = client.list_datasets()\n",
        "\n",
        "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏—Ç–µ—Ä–∞—Ç–æ—Ä –≤ —Å–ø–∏—Å–æ–∫, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑\n",
        "datasets_list = list(datasets)\n",
        "\n",
        "print(f\"–ù–∞–π–¥–µ–Ω–æ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤: {len(datasets_list)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°–ø–æ—Å–æ–± 2: –ü–æ–∏—Å–∫ –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø–æ –∏–º–µ–Ω–∏\n",
        "datasets = client.list_datasets(dataset_name=DATASET_NAME)\n",
        "\n",
        "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏—Ç–µ—Ä–∞—Ç–æ—Ä –≤ —Å–ø–∏—Å–æ–∫, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑\n",
        "datasets_list = list(datasets)\n",
        "\n",
        "print(f\"–ù–∞–π–¥–µ–Ω–æ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤: {len(datasets_list)}\")\n",
        "for dataset in datasets_list:\n",
        "    print(f\"  - {dataset.name} (ID: {dataset.id})\")\n",
        "    if dataset.description:\n",
        "        print(f\"    –û–ø–∏—Å–∞–Ω–∏–µ: {dataset.description}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ RAG —Å LangSmith\n",
        "\n",
        "–í —ç—Ç–æ–º —Ä–∞–∑–¥–µ–ª–µ –º—ã —Å–æ–∑–¥–∞–¥–∏–º –∫–∞—Å—Ç–æ–º–Ω—ã–µ —ç–≤–∞–ª—é–∞—Ç–æ—Ä—ã  –Ω–∞ –æ—Å–Ω–æ–≤–µ LLM-as-a-judge –ø–æ–¥—Ö–æ–¥–∞ –¥–ª—è LangSmith, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ RAG-—Å–∏—Å—Ç–µ–º—ã."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö —ç–≤–∞–ª—é–∞—Ç–æ—Ä–æ–≤\n",
        "\n",
        "–≠–≤–∞–ª—é–∞—Ç–æ—Ä—ã –≤ LangSmith - —ç—Ç–æ —Ñ—É–Ω–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–Ω–∏–º–∞—é—Ç `inputs`, `outputs` –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ `reference_outputs`, –∏ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç –æ—Ü–µ–Ω–∫—É (bool, int –∏–ª–∏ float). –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–¥—Ö–æ–¥ LLM-as-a-judge —Å structured output –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing_extensions import Annotated, TypedDict\n",
        "\n",
        "# Grade output schema –¥–ª—è correctness\n",
        "class CorrectnessGrade(TypedDict):\n",
        "    explanation: Annotated[str, ..., \"Explain your reasoning for the score\"]\n",
        "    score: Annotated[float, ..., \"Score from 0.0 to 1.0 indicating answer correctness\"]\n",
        "\n",
        "# Grade prompt –¥–ª—è correctness\n",
        "correctness_instructions = \"\"\"You are a teacher grading a quiz. You will be given a QUESTION, the GROUND TRUTH (correct) ANSWER, and the STUDENT ANSWER. \n",
        "\n",
        "Grade the student answer based on factual accuracy relative to the ground truth answer.\n",
        "\n",
        "Score:\n",
        "- 1.0: Answer is completely correct and aligns with ground truth\n",
        "- 0.7-0.9: Answer is mostly correct with minor inaccuracies or missing minor details\n",
        "- 0.4-0.6: Answer is partially correct but has significant gaps or some incorrect information\n",
        "- 0.1-0.3: Answer has major inaccuracies or is mostly incorrect\n",
        "- 0.0: Answer is completely incorrect or off-topic\n",
        "\n",
        "Note: It is OK if the student answer contains more information than the ground truth, as long as it is factually accurate.\n",
        "\n",
        "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct.\"\"\"\n",
        "\n",
        "# Grader LLM –¥–ª—è correctness\n",
        "correctness_grader_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0).with_structured_output(\n",
        "    CorrectnessGrade, method=\"json_schema\", strict=True\n",
        ")\n",
        "\n",
        "def answer_correctness(inputs: dict, outputs: dict, reference_outputs: dict) -> float:\n",
        "    \"\"\"–≠–≤–∞–ª—é–∞—Ç–æ—Ä –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ ground truth\"\"\"\n",
        "    answers = f\"\"\"\\\n",
        "QUESTION: {inputs['question']}\n",
        "GROUND TRUTH ANSWER: {reference_outputs['answer']}\n",
        "STUDENT ANSWER: {outputs['answer']}\"\"\"\n",
        "    # Run evaluator\n",
        "    grade = correctness_grader_llm.invoke([\n",
        "        {\"role\": \"system\", \"content\": correctness_instructions},\n",
        "        {\"role\": \"user\", \"content\": answers}\n",
        "    ])\n",
        "    return float(grade[\"score\"])\n",
        "\n",
        "\n",
        "# Grade output schema –¥–ª—è relevance\n",
        "class RelevanceGrade(TypedDict):\n",
        "    explanation: Annotated[str, ..., \"Explain your reasoning for the score\"]\n",
        "    score: Annotated[float, ..., \"Score from 0.0 to 1.0 indicating answer relevance\"]\n",
        "\n",
        "# Grade prompt –¥–ª—è relevance\n",
        "relevance_instructions = \"\"\"You are a teacher grading a quiz. You will be given a QUESTION and a STUDENT ANSWER.\n",
        "\n",
        "Evaluate how relevant and helpful the answer is for the question.\n",
        "\n",
        "Score:\n",
        "- 1.0: Answer is highly relevant, directly addresses the question, and is very helpful\n",
        "- 0.7-0.9: Answer is relevant and mostly addresses the question with minor off-topic content\n",
        "- 0.4-0.6: Answer is somewhat relevant but misses key aspects or has significant off-topic content\n",
        "- 0.1-0.3: Answer is barely relevant, mostly off-topic or unhelpful\n",
        "- 0.0: Answer is completely irrelevant or does not address the question at all\n",
        "\n",
        "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct.\"\"\"\n",
        "\n",
        "# Grader LLM –¥–ª—è relevance\n",
        "relevance_grader_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0).with_structured_output(\n",
        "    RelevanceGrade, method=\"json_schema\", strict=True\n",
        ")\n",
        "\n",
        "def answer_relevancy(inputs: dict, outputs: dict) -> float:\n",
        "    \"\"\"–≠–≤–∞–ª—é–∞—Ç–æ—Ä –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ç–∞ –≤–æ–ø—Ä–æ—Å—É\"\"\"\n",
        "    answer = f\"QUESTION: {inputs['question']}\\nSTUDENT ANSWER: {outputs['answer']}\"\n",
        "    grade = relevance_grader_llm.invoke([\n",
        "        {\"role\": \"system\", \"content\": relevance_instructions},\n",
        "        {\"role\": \"user\", \"content\": answer}\n",
        "    ])\n",
        "    return float(grade[\"score\"])\n",
        "\n",
        "\n",
        "# Grade output schema –¥–ª—è similarity\n",
        "class SimilarityGrade(TypedDict):\n",
        "    explanation: Annotated[str, ..., \"Explain your reasoning for the score\"]\n",
        "    score: Annotated[float, ..., \"Score from 0.0 to 1.0 indicating semantic similarity\"]\n",
        "\n",
        "# Grade prompt –¥–ª—è similarity\n",
        "similarity_instructions = \"\"\"You are a teacher comparing two answers. You will be given a QUESTION, a REFERENCE ANSWER, and a STUDENT ANSWER.\n",
        "\n",
        "Evaluate the semantic similarity between the student answer and the reference answer.\n",
        "\n",
        "Score:\n",
        "- 1.0: Answers convey exactly the same meaning, just with different wording\n",
        "- 0.7-0.9: Answers convey very similar meaning with minor semantic differences\n",
        "- 0.4-0.6: Answers share some common meaning but have notable semantic differences\n",
        "- 0.1-0.3: Answers have little semantic overlap, mostly different meanings\n",
        "- 0.0: Answers convey completely different meanings\n",
        "\n",
        "Note: Focus on semantic meaning, not exact wording. Different words expressing the same idea should score high.\n",
        "\n",
        "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct.\"\"\"\n",
        "\n",
        "# Grader LLM –¥–ª—è similarity\n",
        "similarity_grader_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0).with_structured_output(\n",
        "    SimilarityGrade, method=\"json_schema\", strict=True\n",
        ")\n",
        "\n",
        "def answer_similarity(inputs: dict, outputs: dict, reference_outputs: dict) -> float:\n",
        "    \"\"\"–≠–≤–∞–ª—é–∞—Ç–æ—Ä –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ ground truth\"\"\"\n",
        "    answers = f\"\"\"\\\n",
        "QUESTION: {inputs['question']}\n",
        "REFERENCE ANSWER: {reference_outputs['answer']}\n",
        "STUDENT ANSWER: {outputs['answer']}\"\"\"\n",
        "    # Run evaluator\n",
        "    grade = similarity_grader_llm.invoke([\n",
        "        {\"role\": \"system\", \"content\": similarity_instructions},\n",
        "        {\"role\": \"user\", \"content\": answers}\n",
        "    ])\n",
        "    return float(grade[\"score\"])\n",
        "\n",
        "print(\"‚úì –≠–≤–∞–ª—é–∞—Ç–æ—Ä—ã LangSmith —Å–æ–∑–¥–∞–Ω—ã (–≤—Å–µ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç float 0.0-1.0)\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# –≠–≤–∞–ª—é–∞—Ç–æ—Ä—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º retrieved documents (contexts)\n",
        "# ============================================================================\n",
        "\n",
        "# Grade output schema –¥–ª—è faithfulness (groundedness)\n",
        "class FaithfulnessGrade(TypedDict):\n",
        "    explanation: Annotated[str, ..., \"Explain your reasoning for the score\"]\n",
        "    score: Annotated[float, ..., \"Score from 0.0 to 1.0 indicating how grounded the answer is in the facts\"]\n",
        "\n",
        "# Grade prompt –¥–ª—è faithfulness\n",
        "faithfulness_instructions = \"\"\"You are a teacher grading a quiz. You will be given FACTS and a STUDENT ANSWER. Here is the grade criteria to follow:\n",
        "(1) Ensure the STUDENT ANSWER is grounded in the FACTS\n",
        "(2) Ensure the STUDENT ANSWER does not contain \"hallucinated\" information outside the scope of the FACTS\n",
        "(3) The student can use less information than provided, but cannot add information not in FACTS\n",
        "\n",
        "Score:\n",
        "- 1.0: Answer is fully grounded in the facts with no hallucinations\n",
        "- 0.7-0.9: Answer is mostly grounded with minor unsupported details\n",
        "- 0.4-0.6: Answer has significant unsupported information\n",
        "- 0.1-0.3: Answer is mostly hallucinated\n",
        "- 0.0: Answer is completely hallucinated\n",
        "\n",
        "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct.\"\"\"\n",
        "\n",
        "# Grader LLM –¥–ª—è faithfulness\n",
        "faithfulness_grader_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0).with_structured_output(\n",
        "    FaithfulnessGrade, method=\"json_schema\", strict=True\n",
        ")\n",
        "\n",
        "def faithfulness(inputs: dict, outputs: dict) -> float:\n",
        "    \"\"\"–≠–≤–∞–ª—é–∞—Ç–æ—Ä –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ç–∞ retrieved documents (groundedness)\"\"\"\n",
        "    doc_string = \"\\n\\n\".join(doc.page_content for doc in outputs[\"documents\"])\n",
        "    answer = f\"FACTS:\\n{doc_string}\\n\\nSTUDENT ANSWER: {outputs['answer']}\"\n",
        "    grade = faithfulness_grader_llm.invoke([\n",
        "        {\"role\": \"system\", \"content\": faithfulness_instructions},\n",
        "        {\"role\": \"user\", \"content\": answer}\n",
        "    ])\n",
        "    return float(grade[\"score\"])\n",
        "\n",
        "\n",
        "# Grade output schema –¥–ª—è context_precision (retrieval relevance)\n",
        "class ContextPrecisionGrade(TypedDict):\n",
        "    explanation: Annotated[str, ..., \"Explain your reasoning for the score\"]\n",
        "    score: Annotated[float, ..., \"Score from 0.0 to 1.0 indicating how relevant the retrieved documents are\"]\n",
        "\n",
        "# Grade prompt –¥–ª—è context_precision\n",
        "context_precision_instructions = \"\"\"You are a teacher grading retrieved documents. You will be given a QUESTION and RETRIEVED FACTS. Here is the grade criteria to follow:\n",
        "(1) Evaluate how relevant the FACTS are to answering the QUESTION\n",
        "(2) Check if the FACTS contain information that directly helps answer the QUESTION\n",
        "(3) Consider both relevance and precision of the retrieved information\n",
        "\n",
        "Score:\n",
        "- 1.0: All retrieved facts are highly relevant and precise for the question\n",
        "- 0.7-0.9: Most facts are relevant with some less relevant information\n",
        "- 0.4-0.6: Mix of relevant and irrelevant information\n",
        "- 0.1-0.3: Mostly irrelevant facts\n",
        "- 0.0: No relevant information retrieved\n",
        "\n",
        "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct.\"\"\"\n",
        "\n",
        "# Grader LLM –¥–ª—è context_precision\n",
        "context_precision_grader_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0).with_structured_output(\n",
        "    ContextPrecisionGrade, method=\"json_schema\", strict=True\n",
        ")\n",
        "\n",
        "def context_precision(inputs: dict, outputs: dict) -> float:\n",
        "    \"\"\"–≠–≤–∞–ª—é–∞—Ç–æ—Ä –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ retrieved documents\"\"\"\n",
        "    doc_string = \"\\n\\n\".join(doc.page_content for doc in outputs[\"documents\"])\n",
        "    content = f\"QUESTION: {inputs['question']}\\n\\nRETRIEVED FACTS:\\n{doc_string}\"\n",
        "    grade = context_precision_grader_llm.invoke([\n",
        "        {\"role\": \"system\", \"content\": context_precision_instructions},\n",
        "        {\"role\": \"user\", \"content\": content}\n",
        "    ])\n",
        "    return float(grade[\"score\"])\n",
        "\n",
        "\n",
        "# Grade output schema –¥–ª—è context_recall\n",
        "class ContextRecallGrade(TypedDict):\n",
        "    explanation: Annotated[str, ..., \"Explain your reasoning for the score\"]\n",
        "    score: Annotated[float, ..., \"Score from 0.0 to 1.0 indicating context completeness\"]\n",
        "\n",
        "# Grade prompt –¥–ª—è context_recall\n",
        "context_recall_instructions = \"\"\"You are a teacher checking if retrieved documents contain necessary information. You will be given a QUESTION, the GROUND TRUTH ANSWER, and RETRIEVED FACTS.\n",
        "\n",
        "Your task: Evaluate if the RETRIEVED FACTS contain all the information needed to produce the GROUND TRUTH ANSWER.\n",
        "\n",
        "Score:\n",
        "- 1.0: Retrieved facts contain all information needed for the ground truth answer\n",
        "- 0.7-0.9: Retrieved facts contain most of the needed information\n",
        "- 0.4-0.6: Retrieved facts contain some but not all needed information\n",
        "- 0.1-0.3: Retrieved facts contain very little needed information\n",
        "- 0.0: Retrieved facts do not contain information for the ground truth answer\n",
        "\n",
        "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct.\"\"\"\n",
        "\n",
        "# Grader LLM –¥–ª—è context_recall\n",
        "context_recall_grader_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0).with_structured_output(\n",
        "    ContextRecallGrade, method=\"json_schema\", strict=True\n",
        ")\n",
        "\n",
        "def context_recall(inputs: dict, outputs: dict, reference_outputs: dict) -> float:\n",
        "    \"\"\"–≠–≤–∞–ª—é–∞—Ç–æ—Ä –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–æ–ª–Ω–æ—Ç—ã retrieved documents (—Å–æ–¥–µ—Ä–∂–∞—Ç –ª–∏ –æ–Ω–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞)\"\"\"\n",
        "    doc_string = \"\\n\\n\".join(doc.page_content for doc in outputs[\"documents\"])\n",
        "    content = f\"\"\"\\\n",
        "QUESTION: {inputs['question']}\n",
        "GROUND TRUTH ANSWER: {reference_outputs['answer']}\n",
        "\n",
        "RETRIEVED FACTS:\n",
        "{doc_string}\"\"\"\n",
        "    grade = context_recall_grader_llm.invoke([\n",
        "        {\"role\": \"system\", \"content\": context_recall_instructions},\n",
        "        {\"role\": \"user\", \"content\": content}\n",
        "    ])\n",
        "    return float(grade[\"score\"])\n",
        "\n",
        "print(\"‚úì –≠–≤–∞–ª—é–∞—Ç–æ—Ä—ã —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º —Å–æ–∑–¥–∞–Ω—ã (faithfulness, context_precision, context_recall)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### –ó–∞–ø—É—Å–∫ evaluation –≤ LangSmith\n",
        "\n",
        "–¢–µ–ø–µ—Ä—å –∑–∞–ø—É—Å—Ç–∏–º evaluation –∏—Å–ø–æ–ª—å–∑—É—è –≤—Å–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ —ç–≤–∞–ª—é–∞—Ç–æ—Ä—ã –∏ –¥–∞—Ç–∞—Å–µ—Ç –≤ LangSmith.\n",
        "\n",
        "–í—Å–µ —ç–≤–∞–ª—é–∞—Ç–æ—Ä—ã –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç **float –æ—Ç 0.0 –¥–æ 1.0** –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞.\n",
        "\n",
        "**–≠–≤–∞–ª—é–∞—Ç–æ—Ä—ã –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–æ—Ü–µ–Ω–∫–∞ answer):**\n",
        "- `answer_relevancy` - —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ –≤–æ–ø—Ä–æ—Å—É\n",
        "- `answer_correctness` - –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ ground truth\n",
        "- `answer_similarity` - —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –ø–æ—Ö–æ–∂–µ—Å—Ç—å –Ω–∞ ground truth\n",
        "\n",
        "**–≠–≤–∞–ª—é–∞—Ç–æ—Ä—ã —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º (–æ—Ü–µ–Ω–∫–∞ retrieval):**\n",
        "- `faithfulness` - –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ retrieved documents (–Ω–µ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π)\n",
        "- `context_precision` - —Ç–æ—á–Ω–æ—Å—Ç—å –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å retrieved documents –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞\n",
        "- `context_recall` - –ø–æ–ª–Ω–æ—Ç–∞ retrieved documents (—Å–æ–¥–µ—Ä–∂–∞—Ç –ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –§—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è target –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞\n",
        "def create_target(pipeline):\n",
        "    \"\"\"\n",
        "    –°–æ–∑–¥–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é target –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞\n",
        "    \n",
        "    Args:\n",
        "        pipeline: —Å–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–æ–º 'rag_chain'\n",
        "    \n",
        "    Returns:\n",
        "        —Ñ—É–Ω–∫—Ü–∏—è target –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ client.evaluate()\n",
        "    \"\"\"\n",
        "    def target(inputs: dict) -> dict:\n",
        "        \"\"\"\n",
        "        –§—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç inputs –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ LangSmith\n",
        "        –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç outputs —Å –æ—Ç–≤–µ—Ç–æ–º –∏ retrieved documents –æ—Ç RAG –ø–∞–π–ø–ª–∞–π–Ω–∞.\n",
        "        \n",
        "        Args:\n",
        "            inputs: —Å–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–æ–º 'question'\n",
        "        \n",
        "        Returns:\n",
        "            dict —Å –∫–ª—é—á–∞–º–∏ 'answer' –∏ 'documents'\n",
        "        \"\"\"\n",
        "        question = inputs[\"question\"]\n",
        "        \n",
        "        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã –æ—Ç –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–¥–Ω–∏–º –≤—ã–∑–æ–≤–æ–º\n",
        "        result = pipeline[\"rag_chain\"].invoke({\"question\": question})\n",
        "        \n",
        "        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏ –æ—Ç–≤–µ—Ç, –∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è —ç–≤–∞–ª—é–∞—Ç–æ—Ä–æ–≤ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º\n",
        "        return {\n",
        "            \"answer\": result[\"answer\"],\n",
        "            \"documents\": result[\"documents\"]\n",
        "        }\n",
        "    \n",
        "    return target\n",
        "\n",
        "print(\"‚úì –§—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è target –≥–æ—Ç–æ–≤–∞\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ó–∞–ø—É—Å–∫–∞–µ–º evaluation –≤ LangSmith –¥–ª—è –≤—Å–µ—Ö –ø–∞–π–ø–ª–∞–π–Ω–æ–≤\n",
        "client = Client()\n",
        "\n",
        "langsmith_results = {}\n",
        "\n",
        "for name, pipeline in pipelines.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"–ó–∞–ø—É—Å–∫ evaluation –¥–ª—è {name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # –°–æ–∑–¥–∞–µ–º target —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —ç—Ç–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞\n",
        "    target = create_target(pipeline)\n",
        "    \n",
        "    # –ó–∞–ø—É—Å–∫–∞–µ–º evaluation\n",
        "    experiment_results = client.evaluate(\n",
        "        target,\n",
        "        data=DATASET_NAME,  # –ò–º—è –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
        "        evaluators=[\n",
        "            # –≠–≤–∞–ª—é–∞—Ç–æ—Ä—ã –æ—Ü–µ–Ω–∫–∏ –æ—Ç–≤–µ—Ç–∞ (answer)\n",
        "            answer_relevancy,\n",
        "            answer_correctness,\n",
        "            answer_similarity,\n",
        "            # –≠–≤–∞–ª—é–∞—Ç–æ—Ä—ã –æ—Ü–µ–Ω–∫–∏ –ø–æ–∏—Å–∫–∞ (retrieval)\n",
        "            faithfulness,\n",
        "            context_precision,\n",
        "            context_recall\n",
        "        ],\n",
        "        experiment_prefix=f\"rag-langsmith-{name}\",\n",
        "        metadata={\n",
        "            \"version\": \"LangSmith LLM-as-judge evaluators (6 metrics, all float 0-1)\",\n",
        "            \"pipeline\": name,\n",
        "            \"embedding_model\": pipeline[\"config\"][\"embedding_model\"],\n",
        "            \"llm_model\": pipeline[\"config\"][\"llm_model\"],\n",
        "            \"k\": pipeline[\"config\"][\"k\"],\n",
        "            \"temperature\": pipeline[\"config\"][\"temperature\"],\n",
        "            \"grader_model\": \"gpt-4o\",\n",
        "            \"evaluators\": \"answer_relevancy, answer_correctness, answer_similarity, faithfulness, context_precision, context_recall\"\n",
        "        },\n",
        "    )\n",
        "    \n",
        "    langsmith_results[name] = experiment_results\n",
        "    \n",
        "    print(f\"‚úì Evaluation –¥–ª—è {name} –∑–∞–≤–µ—Ä—à–µ–Ω\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"‚úì –í—Å–µ evaluation –∑–∞–ø—É—â–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ\")\n",
        "print(f\"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤: {len(pipelines)}\")\n",
        "print(f\"  –≠–≤–∞–ª—é–∞—Ç–æ—Ä—ã –æ—Ü–µ–Ω–∫–∏ –æ—Ç–≤–µ—Ç–∞ (float 0-1): answer_relevancy, answer_correctness, answer_similarity\")\n",
        "print(f\"  –≠–≤–∞–ª—é–∞—Ç–æ—Ä—ã –æ—Ü–µ–Ω–∫–∏ –ø–æ–∏—Å–∫–∞ (float 0-1): faithfulness, context_precision, context_recall\")\n",
        "print(f\"\\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ LangSmith UI\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ LangSmith UI\n",
        "\n",
        "–ü–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ evaluation —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ—Å—Ç—É–ø–Ω—ã –≤ LangSmith UI:\n",
        "\n",
        "# ![LangSmith Custom UI](langsmith_custom_ui.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è RAGAS —Å LangSmith —á–µ—Ä–µ–∑ Feedback\n",
        "\n",
        "–í —ç—Ç–æ–º —Ä–∞–∑–¥–µ–ª–µ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º **–≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥**: –∑–∞–ø—É—Å–∫–∞–µ–º RAG –ø–∞–π–ø–ª–∞–π–Ω –≤ LangSmith –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è traces, –∑–∞—Ç–µ–º –≤—ã—á–∏—Å–ª—è–µ–º RAGAS –º–µ—Ç—Ä–∏–∫–∏ –≤ batch —Ä–µ–∂–∏–º–µ, –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞–∫ feedback –≤ LangSmith.\n",
        "\n",
        "**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —ç—Ç–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞:**\n",
        "- –ò—Å–ø–æ–ª—å–∑—É–µ–º —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π batch processing –æ—Ç RAGAS\n",
        "- –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ traces –≤ LangSmith\n",
        "- –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è –≤ LangSmith UI –∫–∞–∫ feedback\n",
        "- –ú–æ–∂–µ–º —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –≤ –µ–¥–∏–Ω–æ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ\n",
        "\n",
        "**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**\n",
        "1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º RAGAS –º–µ—Ç—Ä–∏–∫–∏ –æ–¥–∏–Ω —Ä–∞–∑\n",
        "2. –°–æ–∑–¥–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è evaluation –æ–¥–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞\n",
        "3. –ó–∞–ø—É—Å–∫–∞–µ–º evaluation –¥–ª—è –≤—Å–µ—Ö –ø–∞–π–ø–ª–∞–π–Ω–æ–≤ –≤ —Ü–∏–∫–ª–µ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAGAS –º–µ—Ç—Ä–∏–∫\n",
        "\n",
        "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º RAGAS –º–µ—Ç—Ä–∏–∫–∏ **–æ–¥–∏–Ω —Ä–∞–∑** –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    Faithfulness,\n",
        "    ResponseRelevancy,\n",
        "    ContextRecall,\n",
        "    ContextPrecision,\n",
        "    AnswerCorrectness,\n",
        "    AnswerSimilarity,\n",
        ")\n",
        "from ragas.metrics.base import MetricWithLLM, MetricWithEmbeddings\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from ragas.run_config import RunConfig\n",
        "\n",
        "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ RAGAS –º–µ—Ç—Ä–∏–∫ (–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ Langfuse)\n",
        "def init_ragas_metrics(metrics, llm, embedding):\n",
        "    \"\"\"\n",
        "    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç RAGAS –º–µ—Ç—Ä–∏–∫–∏ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ LLM –∏ embeddings.\n",
        "    \n",
        "    Args:\n",
        "        metrics: —Å–ø–∏—Å–æ–∫ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏\n",
        "        llm: LLM –¥–ª—è –º–µ—Ç—Ä–∏–∫, —Ç—Ä–µ–±—É—é—â–∏—Ö language model\n",
        "        embedding: embeddings –¥–ª—è –º–µ—Ç—Ä–∏–∫, —Ç—Ä–µ–±—É—é—â–∏—Ö embeddings\n",
        "    \"\"\"\n",
        "    for metric in metrics:\n",
        "        if isinstance(metric, MetricWithLLM):\n",
        "            metric.llm = llm\n",
        "        if isinstance(metric, MetricWithEmbeddings):\n",
        "            metric.embeddings = embedding\n",
        "        run_config = RunConfig()\n",
        "        metric.init(run_config)\n",
        "\n",
        "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LLM –∏ embeddings –¥–ª—è RAGAS (–æ–¥–∏–Ω —Ä–∞–∑ –¥–ª—è –≤—Å–µ—Ö –ø–∞–π–ø–ª–∞–π–Ω–æ–≤)\n",
        "langchain_llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
        "langchain_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
        "ragas_metrics = [\n",
        "    Faithfulness(),\n",
        "    ResponseRelevancy(),\n",
        "    AnswerCorrectness(),\n",
        "    AnswerSimilarity(),\n",
        "    ContextRecall(),\n",
        "    ContextPrecision(),\n",
        "]\n",
        "\n",
        "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
        "init_ragas_metrics(\n",
        "    ragas_metrics,\n",
        "    llm=LangchainLLMWrapper(langchain_llm),\n",
        "    embedding=LangchainEmbeddingsWrapper(langchain_embeddings),\n",
        ")\n",
        "\n",
        "# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–≥–æ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n",
        "ragas_run_config = RunConfig(\n",
        "    max_workers=4,\n",
        "    max_wait=180,\n",
        "    max_retries=3\n",
        ")\n",
        "\n",
        "print(\"‚úì RAGAS –º–µ—Ç—Ä–∏–∫–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã\")\n",
        "print(f\"  –ú–µ—Ç—Ä–∏–∫–∏: {', '.join([m.name for m in ragas_metrics])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 –§—É–Ω–∫—Ü–∏—è evaluation –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞\n",
        "\n",
        "–°–æ–∑–¥–∞–µ–º **—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—É—é** —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª evaluation –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞:\n",
        "1. –ó–∞–ø—É—Å–∫–∞–µ—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –≤ LangSmith —Å `blocking=False` –∏ —Å–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n",
        "2. –ó–∞–ø—É—Å–∫–∞–µ—Ç RAGAS evaluation\n",
        "3. –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∫–∞–∫ feedback –≤ LangSmith\n",
        "\n",
        "**–ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞:**\n",
        "- –ü—Ä–∏–Ω–∏–º–∞–µ—Ç `target` —Ñ—É–Ω–∫—Ü–∏—é, –∞ –Ω–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–π–ø–ª–∞–π–Ω–∞\n",
        "- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ `metadata` dict (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
        "- –†–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±—ã–º –¥–∞—Ç–∞—Å–µ—Ç–æ–º —á–µ—Ä–µ–∑ `dataset_name`\n",
        "- –ú–æ–∂–µ—Ç –±—ã—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ —Å –ª—é–±—ã–º RAG –ø–∞–π–ø–ª–∞–π–Ω–æ–º, –∫–æ—Ç–æ—Ä—ã–π –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç `answer` –∏ `documents`\n",
        "- **–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π LangSmith Python SDK** —Å `blocking=False` –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "- –°—Å—ã–ª–∫–∞ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é: [LangSmith SDK Evaluation](https://reference.langchain.com/python/langsmith/observability/sdk/evaluation/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_pipeline_with_ragas_feedback(\n",
        "    pipeline_name: str, \n",
        "    target: callable,\n",
        "    dataset_name: str,\n",
        "    metadata: dict = None\n",
        "):\n",
        "    \"\"\"\n",
        "    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª evaluation –¥–ª—è –æ–¥–Ω–æ–≥–æ RAG –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RAGAS –∏ LangSmith.\n",
        "    \n",
        "    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω-–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å –ª—é–±—ã–º RAG –ø–∞–π–ø–ª–∞–π–Ω–æ–º.\n",
        "    \n",
        "    Steps:\n",
        "        1. –ó–∞–ø—É—Å–∫–∞–µ—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –≤ LangSmith —Å blocking=False –∏ —Å–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ runs \n",
        "           –ø–æ –º–µ—Ä–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (–∏—Ç–µ—Ä–∞—Ü–∏—è –ø–æ ExperimentResultRow)\n",
        "        2. –ó–∞–ø—É—Å–∫–∞–µ—Ç RAGAS batch evaluation –Ω–∞ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "        3. –ó–∞–≥—Ä—É–∂–∞–µ—Ç RAGAS –º–µ—Ç—Ä–∏–∫–∏ –∫–∞–∫ feedback –≤ LangSmith\n",
        "    \n",
        "    Technical Details:\n",
        "        - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç client.evaluate() —Å blocking=False –¥–ª—è –∏—Ç–µ—Ä–∞—Ü–∏–∏ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º\n",
        "        - –ö–∞–∂–¥—ã–π result —Å–æ–¥–µ—Ä–∂–∏—Ç Run (—Å inputs/outputs) –∏ Example (—Å ground truth)\n",
        "        - –°–ª–µ–¥—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ LangSmith SDK: https://reference.langchain.com/python/langsmith/\n",
        "    \n",
        "    Args:\n",
        "        pipeline_name: –∏–º—è –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
        "        target: callable —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç dict —Å 'question' –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å 'answer' –∏ 'documents'\n",
        "        dataset_name: –∏–º—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ LangSmith –¥–ª—è evaluation\n",
        "        metadata: –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ (embedding_model, llm_model, k, temperature, –∏ —Ç.–¥.)\n",
        "    \n",
        "    Returns:\n",
        "        dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ evaluation:\n",
        "            - pipeline_name: –∏–º—è –ø–∞–π–ø–ª–∞–π–Ω–∞\n",
        "            - ragas_result: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã RAGAS evaluation\n",
        "            - num_examples: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤\n",
        "            - run_ids: —Å–ø–∏—Å–æ–∫ ID runs –≤ LangSmith\n",
        "    \n",
        "    Example:\n",
        "        >>> target = lambda inputs: my_rag_pipeline(inputs[\"question\"])\n",
        "        >>> result = evaluate_pipeline_with_ragas_feedback(\n",
        "        ...     pipeline_name=\"my_pipeline\",\n",
        "        ...     target=target,\n",
        "        ...     dataset_name=\"MY_DATASET\",\n",
        "        ...     metadata={\"version\": \"1.0\", \"model\": \"gpt-4\"}\n",
        "        ... )\n",
        "    \"\"\"\n",
        "    if metadata is None:\n",
        "        metadata = {}\n",
        "    \n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Evaluation –¥–ª—è {pipeline_name}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –í–û –í–†–ï–ú–Ø –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è evaluate\n",
        "    # client.evaluate() –∏—Ç–µ—Ä–∏—Ä—É–µ–º—ã–π - –æ–Ω –≤—ã–¥–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–µ—Ä–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n",
        "    questions = []\n",
        "    answers = []\n",
        "    contexts_list = []\n",
        "    ground_truths = []\n",
        "    run_ids = []\n",
        "    \n",
        "    print(f\"\\n[1/3] –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –∏ —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö...\")\n",
        "    \n",
        "    # evaluate() —Å blocking=False –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Ç–µ—Ä–∞—Ç–æ—Ä –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º\n",
        "    # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: https://reference.langchain.com/python/langsmith/observability/sdk/evaluation/\n",
        "    for result in client.evaluate(\n",
        "        target,\n",
        "        data=dataset_name,\n",
        "        evaluators=[],  # –ë–µ–∑ evaluators\n",
        "        experiment_prefix=f\"rag-ragas-feedback-{pipeline_name}\",\n",
        "        metadata={\n",
        "            \"approach\": \"RAGAS batch evaluation + LangSmith feedback\",\n",
        "            \"pipeline\": pipeline_name,\n",
        "            **metadata  # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\n",
        "        },\n",
        "        blocking=False,  # ‚Üê –í–ê–ñ–ù–û: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Ç–µ—Ä–∞—Ç–æ—Ä –≤–º–µ—Å—Ç–æ ExperimentResults\n",
        "    ):\n",
        "        # result —ç—Ç–æ ExperimentResultRow - dict —Å –∫–ª—é—á–∞–º–∏ 'run' –∏ 'example'\n",
        "        # run: Run –æ–±—ä–µ–∫—Ç —Å inputs, outputs, id\n",
        "        # example: Example –æ–±—ä–µ–∫—Ç —Å outputs (ground truth)\n",
        "        run = result[\"run\"]\n",
        "        example = result[\"example\"]\n",
        "        \n",
        "        # –ü–æ–ª—É—á–∞–µ–º question –∏–∑ inputs\n",
        "        question = run.inputs.get(\"question\", \"\")\n",
        "        \n",
        "        # –ü–æ–ª—É—á–∞–µ–º answer –∏–∑ outputs\n",
        "        answer = run.outputs.get(\"answer\", \"\")\n",
        "        \n",
        "        # –ü–æ–ª—É—á–∞–µ–º contexts –∏–∑ documents –≤ outputs\n",
        "        documents = run.outputs.get(\"documents\", [])\n",
        "        contexts = [doc.page_content if hasattr(doc, 'page_content') else str(doc) for doc in documents]\n",
        "        \n",
        "        # –ü–æ–ª—É—á–∞–µ–º ground_truth –∏–∑ example\n",
        "        ground_truth = example.outputs.get(\"answer\", \"\") if example else \"\"\n",
        "        \n",
        "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ\n",
        "        questions.append(question)\n",
        "        answers.append(answer)\n",
        "        contexts_list.append(contexts)\n",
        "        ground_truths.append(ground_truth)\n",
        "        run_ids.append(str(run.id))\n",
        "    \n",
        "    print(f\"‚úì –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω, —Å–æ–±—Ä–∞–Ω–æ {len(questions)} –ø—Ä–∏–º–µ—Ä–æ–≤\")\n",
        "    \n",
        "    # ========== –®–∞–≥ 2: RAGAS evaluation ==========\n",
        "    print(f\"\\n[2/3] –ó–∞–ø—É—Å–∫ RAGAS evaluation...\")\n",
        "    \n",
        "    # –°–æ–∑–¥–∞–µ–º Dataset –¥–ª—è RAGAS\n",
        "    ragas_dataset = Dataset.from_dict({\n",
        "        \"question\": questions,\n",
        "        \"answer\": answers,\n",
        "        \"contexts\": contexts_list,\n",
        "        \"ground_truth\": ground_truths\n",
        "    })\n",
        "    \n",
        "    # –ó–∞–ø—É—Å–∫–∞–µ–º evaluation (–º–µ—Ç—Ä–∏–∫–∏ —É–∂–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã!)\n",
        "    ragas_result = evaluate(\n",
        "        ragas_dataset,\n",
        "        metrics=ragas_metrics,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
        "        run_config=ragas_run_config,\n",
        "    )\n",
        "    \n",
        "    ragas_df = ragas_result.to_pandas()\n",
        "    \n",
        "    print(f\"‚úì RAGAS evaluation –∑–∞–≤–µ—Ä—à–µ–Ω\")\n",
        "    print(f\"\\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã RAGAS –¥–ª—è {pipeline_name}:\")\n",
        "    for metric in ragas_metrics:\n",
        "        if metric.name in ragas_df.columns:\n",
        "            print(f\"  {metric.name}: {ragas_df[metric.name].mean():.3f}\")\n",
        "    \n",
        "    # ========== –®–∞–≥ 3: –ó–∞–≥—Ä—É–∑–∫–∞ feedback –≤ LangSmith ==========\n",
        "    print(f\"\\n[3/3] –ó–∞–≥—Ä—É–∑–∫–∞ feedback –≤ LangSmith...\")\n",
        "    \n",
        "    for idx, run_id in enumerate(run_ids):\n",
        "        row = ragas_df.iloc[idx]\n",
        "        \n",
        "        # –°–æ–∑–¥–∞–µ–º feedback –¥–ª—è –∫–∞–∂–¥–æ–π –º–µ—Ç—Ä–∏–∫–∏\n",
        "        for metric in ragas_metrics:\n",
        "            if metric.name in row:\n",
        "                score = row[metric.name]\n",
        "                client.create_feedback(\n",
        "                    run_id=run_id,\n",
        "                    key=f\"{metric.name}\",\n",
        "                    score=float(score),\n",
        "                    comment=f\"RAGAS metric: {metric.name}\"\n",
        "                )\n",
        "    \n",
        "    print(f\"‚úì Feedback –∑–∞–≥—Ä—É–∂–µ–Ω ({len(run_ids)} runs)\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "    \n",
        "    return {\n",
        "        \"pipeline_name\": pipeline_name,\n",
        "        \"ragas_result\": ragas_result,\n",
        "        \"num_examples\": len(questions),\n",
        "        \"run_ids\": run_ids\n",
        "    }\n",
        "\n",
        "print(\"‚úì –§—É–Ω–∫—Ü–∏—è evaluate_pipeline_with_ragas_feedback —Å–æ–∑–¥–∞–Ω–∞\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ\n",
        "\n",
        "–§—É–Ω–∫—Ü–∏—è `evaluate_pipeline_with_ragas_feedback` —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞ –∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ —Å –ª—é–±—ã–º RAG –ø–∞–π–ø–ª–∞–π–Ω–æ–º:\n",
        "\n",
        "```python\n",
        "# –ü—Ä–∏–º–µ—Ä 1: –ü—Ä–æ—Å—Ç–æ–π RAG –ø–∞–π–ø–ª–∞–π–Ω\n",
        "def my_rag_pipeline(question: str) -> dict:\n",
        "    # –í–∞—à –∫–æ–¥ RAG –ø–∞–π–ø–ª–∞–π–Ω–∞\n",
        "    retrieved_docs = retriever.get_relevant_documents(question)\n",
        "    answer = llm.generate(question, retrieved_docs)\n",
        "    return {\"answer\": answer, \"documents\": retrieved_docs}\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º target —Ñ—É–Ω–∫—Ü–∏—é\n",
        "target = lambda inputs: my_rag_pipeline(inputs[\"question\"])\n",
        "\n",
        "# –ó–∞–ø—É—Å–∫–∞–µ–º evaluation\n",
        "result = evaluate_pipeline_with_ragas_feedback(\n",
        "    pipeline_name=\"my_production_pipeline_v1\",\n",
        "    target=target,\n",
        "    dataset_name=\"MY_PRODUCTION_DATASET\",\n",
        "    metadata={\n",
        "        \"version\": \"1.0\",\n",
        "        \"model\": \"gpt-4\",\n",
        "        \"retriever\": \"chroma\",\n",
        "        \"k\": 5\n",
        "    }\n",
        ")\n",
        "```\n",
        "\n",
        "### 5.3 –ó–∞–ø—É—Å–∫ evaluation –¥–ª—è –≤—Å–µ—Ö –ø–∞–π–ø–ª–∞–π–Ω–æ–≤\n",
        "\n",
        "–¢–µ–ø–µ—Ä—å –∑–∞–ø—É—Å–∫–∞–µ–º evaluation –¥–ª—è –Ω–∞—à–∏—Ö —É—á–µ–±–Ω—ã—Ö –ø–∞–π–ø–ª–∞–π–Ω–æ–≤, –≤—ã–∑—ã–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—é –≤ —Ü–∏–∫–ª–µ.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ó–∞–ø—É—Å–∫–∞–µ–º evaluation –¥–ª—è –≤—Å–µ—Ö –ø–∞–π–ø–ª–∞–π–Ω–æ–≤\n",
        "ragas_feedback_results = {}\n",
        "\n",
        "for name, pipeline in pipelines.items():\n",
        "    # –°–æ–∑–¥–∞–µ–º target —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —ç—Ç–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞\n",
        "    target = create_target(pipeline)\n",
        "    \n",
        "    # –ó–∞–ø—É—Å–∫–∞–µ–º evaluation\n",
        "    result = evaluate_pipeline_with_ragas_feedback(\n",
        "        pipeline_name=name,\n",
        "        target=target,\n",
        "        dataset_name=DATASET_NAME,\n",
        "        metadata=pipeline[\"config\"]  # –ü–µ—Ä–µ–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∫–∞–∫ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\n",
        "    )\n",
        "    ragas_feedback_results[name] = result\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"‚úÖ Evaluation –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è –≤—Å–µ—Ö –ø–∞–π–ø–ª–∞–π–Ω–æ–≤\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"\\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤: {len(ragas_feedback_results)}\")\n",
        "print(f\"RAGAS –º–µ—Ç—Ä–∏–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∫–∞–∫ feedback –≤ LangSmith\")\n",
        "print(f\"\\nüëâ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ LangSmith UI:\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4 –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ LangSmith UI\n",
        " \n",
        "–ü–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ evaluation —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ—Å—Ç—É–ø–Ω—ã –≤ LangSmith UI:\n",
        "\n",
        "![LangSmith RAGAS UI](langsmith_ragas_ui.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6 –ò—Ç–æ–≥–∏: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–æ–≤ –∫ evaluation\n",
        "\n",
        "–ú—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–ª–∏ —Ç—Ä–∏ –ø–æ–¥—Ö–æ–¥–∞ –∫ evaluation RAG —Å–∏—Å—Ç–µ–º:\n",
        "\n",
        "**1. RAGAS (–†–∞–∑–¥–µ–ª 3)**\n",
        "- ‚úÖ Batch processing - –±—ã—Å—Ç—Ä–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫\n",
        "- ‚úÖ –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è RAG\n",
        "- ‚úÖ –ü—Ä–æ—Å—Ç–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤ pandas/matplotlib\n",
        "- ‚ùå –ù–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã—Ö traces\n",
        "- ‚ùå –°–ª–æ–∂–Ω–æ –æ—Ç–ª–∞–∂–∏–≤–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—ã\n",
        "\n",
        "**2. LangSmith —Å custom evaluators (–†–∞–∑–¥–µ–ª 4)**\n",
        "- ‚úÖ –î–µ—Ç–∞–ª—å–Ω—ã–µ traces –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞\n",
        "- ‚úÖ –£–¥–æ–±–Ω—ã–π UI –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\n",
        "- ‚úÖ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤\n",
        "- ‚ùå –ù—É–∂–Ω–æ –ø–∏—Å–∞—Ç—å evaluators –≤—Ä—É—á–Ω—É—é\n",
        "- ‚ùå –ú–µ–¥–ª–µ–Ω–Ω–µ–µ —á–µ–º batch RAGAS\n",
        "\n",
        "**3. LangSmith —Å RAGAS —á–µ—Ä–µ–∑ feedback (–†–∞–∑–¥–µ–ª 5)**\n",
        "- ‚úÖ –ë—ã—Å—Ç—Ä–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ (RAGAS batch)\n",
        "- ‚úÖ –î–µ—Ç–∞–ª—å–Ω—ã–µ traces (LangSmith)\n",
        "- ‚úÖ –£–¥–æ–±–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (LangSmith UI)\n",
        "- ‚úÖ –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (RAGAS)\n",
        "- ‚úÖ –ú–æ–∂–Ω–æ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã\n",
        "- ‚ö†Ô∏è –î–≤—É—Ö—à–∞–≥–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å (—Å–Ω–∞—á–∞–ª–∞ traces, –ø–æ—Ç–æ–º feedback)\n",
        "\n",
        "**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**\n",
        "- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ **RAGAS** –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤\n",
        "- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ **LangSmith** –¥–ª—è production –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –æ—Ç–ª–∞–¥–∫–∏\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
