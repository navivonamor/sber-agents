{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Advanced Hybrid RAG —Å Cross-Encoder Reranking\n",
        "\n",
        "–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π RAG –ø–∞–π–ø–ª–∞–π–Ω: Hybrid retrieval (Semantic + BM25) + Cross-encoder reranking\n",
        "\n",
        "**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**\n",
        "- üè† –õ–æ–∫–∞–ª—å–Ω—ã–µ embeddings (HuggingFace E5)\n",
        "- üîç Part 1: Hybrid RAG (Semantic + BM25)\n",
        "- üéØ Part 2: + Cross-encoder reranking\n",
        "- üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –≤ LangSmith\n",
        "\n",
        "---\n",
        "\n",
        "## üîß –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏ (multilingual —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä—É—Å—Å–∫–æ–≥–æ)\n",
        "\n",
        "| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –ú–æ–¥–µ–ª—å | –ü–∞—Ä–∞–º–µ—Ç—Ä—ã | –†–∞–∑–º–µ—Ä | Retrieval Score | Rank |\n",
        "|-----------|--------|-----------|--------|----------------|------|\n",
        "| **Embeddings** | `intfloat/multilingual-e5-base` | 278M | 1.1 GB | 67.14 / 100 | #32 –∏–∑ 180 |\n",
        "| **Cross-Encoder** | `cross-encoder/mmarco-mMiniLMv2-L12-H384-v1` | 117.6M | 470 MB | multilingual | - |\n",
        "\n",
        "**–ü–æ—á–µ–º—É —ç—Ç–∏ –º–æ–¥–µ–ª–∏?**\n",
        "- Retrieval 67.14 - —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è —Ä–∞–∑–º–µ—Ä–∞\n",
        "- –†–∞–±–æ—Ç–∞—é—Ç –Ω–∞ CPU –±–µ–∑ GPU\n",
        "- 100+ —è–∑—ã–∫–æ–≤ –≤–∫–ª—é—á–∞—è —Ä—É—Å—Å–∫–∏–π\n",
        "- –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–æ/—Ä–µ—Å—É—Ä—Å—ã\n",
        "- –¢–æ–ø-1 –º–æ–¥–µ–ª—å (81.15) –≤ 12x —Ç—è–∂–µ–ª–µ–µ –ø—Ä–∏ +14 –ø—É–Ω–∫—Ç–∞—Ö –∫–∞—á–µ—Å—Ç–≤–∞\n",
        "\n",
        "## üíª –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ä–µ—Å—É—Ä—Å–∞–º\n",
        "\n",
        "**–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ (–¥–ª—è –∑–∞–ø—É—Å–∫–∞ –Ω–∞ CPU):**\n",
        "- RAM: 4-6 GB —Å–≤–æ–±–æ–¥–Ω–æ–π –ø–∞–º—è—Ç–∏\n",
        "- CPU: 4 —è–¥—Ä–∞\n",
        "\n",
        "**–†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ:**\n",
        "- RAM: 8-16 GB\n",
        "- CPU: 8+ —è–¥–µ—Ä —Å AVX2\n",
        "\n",
        "**GPU –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è!** ‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–∞ CPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU langchain langchain-classic langchain-openai langchain-community langchain-core langchain-text-splitters langchain-huggingface\n",
        "%pip install -qU pypdf python-dotenv rank-bm25\n",
        "%pip install -qU langsmith ragas datasets sentence-transformers pandas matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\"\n",
        "assert os.getenv(\"LANGSMITH_API_KEY\"), \"LANGSMITH_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\"\n",
        "\n",
        "# –û—Ç–∫–ª—é—á–∞–µ–º warning –æ—Ç tokenizers (–≤–æ–∑–Ω–∏–∫–∞–µ—Ç –ø—Ä–∏ fork –ø–æ—Å–ª–µ parallelism)\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "print(\"‚úì –û–∫—Ä—É–∂–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import InMemoryVectorStore\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain_classic.retrievers import EnsembleRetriever\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "from langsmith import Client\n",
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    Faithfulness,\n",
        "    ResponseRelevancy,\n",
        "    AnswerCorrectness,\n",
        "    AnswerSimilarity,\n",
        "    ContextRecall,\n",
        "    ContextPrecision,\n",
        ")\n",
        "from ragas.metrics.base import MetricWithLLM, MetricWithEmbeddings\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from ragas.run_config import RunConfig\n",
        "from datasets import Dataset\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(\"‚úì –ò–º–ø–æ—Ä—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_pdf_documents(data_dir: str) -> List:\n",
        "    pages = []\n",
        "    for pdf_file in Path(data_dir).glob(\"*.pdf\"):\n",
        "        pages.extend(PyPDFLoader(str(pdf_file)).load())\n",
        "    return pages\n",
        "\n",
        "def split_documents(pages: List, chunk_size: int = 500, chunk_overlap: int = 50) -> List:\n",
        "    return RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    ).split_documents(pages)\n",
        "\n",
        "pages = load_pdf_documents(\"documents\")\n",
        "chunks = split_documents(pages)\n",
        "\n",
        "print(f\"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(pages)} —Å—Ç—Ä–∞–Ω–∏—Ü ‚Üí {len(chunks)} —á–∞–Ω–∫–æ–≤\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Hybrid RAG (Semantic + BM25)\n",
        "\n",
        "–°–æ–∑–¥–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω —Å –≥–∏–±—Ä–∏–¥–Ω—ã–º –ø–æ–∏—Å–∫–æ–º –±–µ–∑ reranking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìö –ö–∞–∫ –≤—ã–±—Ä–∞—Ç—å embedding –º–æ–¥–µ–ª—å:\n",
        "# 1. –û—Ç–∫—Ä–æ–π https://huggingface.co/spaces/mteb/leaderboard\n",
        "# 2. –û—Ç—Å–æ—Ä—Ç–∏—Ä—É–π—Ç–µ —Ä–µ–π—Ç–∏–Ω–≥ –ø–æ –∫–æ–ª–æ–Ω–∫–µ \"Retrieval\" (–≥–ª–∞–≤–Ω–∞—è –¥–ª—è RAG)\n",
        "# 3. –§–∏–ª—å—Ç—Ä Language-specific \"Russian\" –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞\n",
        "#\n",
        "# –¢–æ–ø –º–æ–¥–µ–ª–µ–π –ø–æ MTEB(rus) Retrieval –º–µ—Ç—Ä–∏–∫–µ (–≥–ª–∞–≤–Ω–∞—è –¥–ª—è RAG):\n",
        "#\n",
        "# –¢–æ–ø-5 –ø–æ –∫–∞—á–µ—Å—Ç–≤—É Retrieval:\n",
        "# 1. Giga-Embeddings-instruct (3B, 12.9GB) - Retrieval: 81.15 ü•á [—Å–ª–∏—à–∫–æ–º —Ç—è–∂–µ–ª–∞—è]\n",
        "# 2. FRIDA (823M, 3.1GB) - Retrieval: 77.17 ü•à [—Ö–æ—Ä–æ—à–æ –¥–ª—è —Å–µ—Ä–≤–µ—Ä–∞]\n",
        "# 3. GritLM-7B (7B, 13.8GB) - Retrieval: 75.79 ü•â [–æ—á–µ–Ω—å —Ç—è–∂–µ–ª–∞—è]\n",
        "# 4. bge-m3 (568M, 2.2GB) - Retrieval: 74.79 [–æ—Ç–ª–∏—á–Ω–æ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ]\n",
        "# 5. e5-mistral-7b-instruct (7B, 13.6GB) - Retrieval: 74.19 [—Ç—è–∂–µ–ª–∞—è]\n",
        "#\n",
        "# –°–µ–º–µ–π—Å—Ç–≤–æ E5 (–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã –¥–ª—è CPU):\n",
        "# ‚Ä¢ multilingual-e5-large-instruct (560M, 1.1GB) - Retrieval: 68.23, Rank #7\n",
        "# ‚Ä¢ multilingual-e5-base (278M, 1.1GB) - Retrieval: 67.14, Rank #32 ‚≠ê –ù–ê–® –í–´–ë–û–†\n",
        "# ‚Ä¢ multilingual-e5-small (118M, 449MB) - Retrieval: 65.85, Rank #37\n",
        "#\n",
        "# üí° –ü–æ—á–µ–º—É multilingual-e5-base –æ–ø—Ç–∏–º–∞–ª–µ–Ω:\n",
        "# ‚úÖ Retrieval 67.14 - —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è —Ä–∞–∑–º–µ—Ä–∞\n",
        "# ‚úÖ –¢–æ–ª—å–∫–æ 1.1 GB –ø–∞–º—è—Ç–∏ - —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ CPU\n",
        "# ‚úÖ 100+ —è–∑—ã–∫–æ–≤ –≤–∫–ª—é—á–∞—è —Ä—É—Å—Å–∫–∏–π\n",
        "# ‚úÖ –†–∞–∑–Ω–∏—Ü–∞ —Å —Ç–æ–ø-1: -14 –ø—É–Ω–∫—Ç–æ–≤, –Ω–æ –≤ 12x –ª–µ–≥—á–µ (1.1GB vs 12.9GB)\n",
        "#\n",
        "# üéØ –°–æ–∑–¥–∞–µ–º embedding –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å–º—ã—Å–ª–∞ —Ç–µ–∫—Å—Ç–∞\n",
        "# –ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –≤ –≤–µ–∫—Ç–æ—Ä—ã: –ø–æ—Ö–æ–∂–∏–µ –ø–æ —Å–º—ã—Å–ª—É —Ç–µ–∫—Å—Ç—ã ‚Üí –ø–æ—Ö–æ–∂–∏–µ –≤–µ–∫—Ç–æ—Ä—ã\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"intfloat/multilingual-e5-base\",  # –ú–æ–¥–µ–ª—å —Å HuggingFace\n",
        "    model_kwargs={'device': 'cpu'},  # 'cuda' –¥–ª—è GPU, 'mps' –¥–ª—è Mac M1/M2\n",
        "    encode_kwargs={'normalize_embeddings': True}  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞\n",
        "    # –ü–æ–ª–µ–∑–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: batch_size=32 (–¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤), show_progress=True\n",
        ")\n",
        "\n",
        "# üîç Semantic retriever - –ø–æ–∏—Å–∫ –ø–æ —Å–º—ã—Å–ª—É —á–µ—Ä–µ–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ\n",
        "# –ù–∞—Ö–æ–¥–∏—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –±–ª–∏–∑–∫–∏–µ –ø–æ –∑–Ω–∞—á–µ–Ω–∏—é, –¥–∞–∂–µ –µ—Å–ª–∏ —Å–ª–æ–≤–∞ —Ä–∞–∑–Ω—ã–µ\n",
        "vector_store = InMemoryVectorStore.from_documents(chunks, embeddings)\n",
        "semantic_retriever = vector_store.as_retriever(\n",
        "    search_type=\"similarity\",  # \"similarity\" (default), \"mmr\" (—Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ), \"similarity_score_threshold\" (—Å –ø–æ—Ä–æ–≥–æ–º)\n",
        "    search_kwargs={\n",
        "        \"k\": 10  # –¢–æ–ø-10 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "        # \"score_threshold\": 0.5,  # –ü–æ—Ä–æ–≥ similarity score (0-1), —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å search_type=\"similarity_score_threshold\"\n",
        "        # \"fetch_k\": 20,  # –î–ª—è MMR: —Å–Ω–∞—á–∞–ª–∞ –±–µ—Ä–µ–º 20, –ø–æ—Ç–æ–º MMR –≤—ã–±–∏—Ä–∞–µ—Ç 10 —Å–∞–º—ã—Ö —Ä–∞–∑–Ω—ã—Ö\n",
        "        # \"lambda_mult\": 0.5,  # –î–ª—è MMR: –±–∞–ª–∞–Ω—Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å/—Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ (0=–º–∞–∫—Å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ, 1=–º–∞–∫—Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å)\n",
        "    }\n",
        ")\n",
        "\n",
        "# üìä BM25 retriever - –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ —Ç–æ—á–Ω—ã–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è–º —Å–ª–æ–≤\n",
        "# –•–æ—Ä–æ—à–æ –Ω–∞—Ö–æ–¥–∏—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã, –Ω–æ–º–µ—Ä–∞, –Ω–∞–∑–≤–∞–Ω–∏—è\n",
        "bm25_retriever = BM25Retriever.from_documents(chunks)\n",
        "bm25_retriever.k = 10  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "\n",
        "# üéØ Ensemble - –æ–±—ä–µ–¥–∏–Ω—è–µ–º –æ–±–∞ –ø–æ–¥—Ö–æ–¥–∞ (–≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫)\n",
        "# Semantic –ª–æ–≤–∏—Ç —Å–∏–Ω–æ–Ω–∏–º—ã, BM25 –ª–æ–≤–∏—Ç —Ç–æ—á–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã\n",
        "# RRF (Reciprocal Rank Fusion) –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –≤–µ—Å–∞–º–∏ 50/50\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=[semantic_retriever, bm25_retriever],\n",
        "    weights=[0.5, 0.5]  # –í–µ—Å–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ retriever (—Å—É–º–º–∞ = 1.0)\n",
        "    # –ú–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å: [0.7, 0.3] –µ—Å–ª–∏ semantic –≤–∞–∂–Ω–µ–µ, [0.3, 0.7] –µ—Å–ª–∏ BM25 –≤–∞–∂–Ω–µ–µ\n",
        ")\n",
        "\n",
        "print(\"‚úì Hybrid retrieval –≥–æ—Ç–æ–≤ (Semantic + BM25)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LLM –∏ –ø—Ä–æ–º–ø—Ç\n",
        "llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0.0)\n",
        "\n",
        "SYSTEM_TEMPLATE = \"\"\"–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.\n",
        "–ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.\n",
        "–ï—Å–ª–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–µ—Ç, —Å–∫–∞–∂–∏ \"–Ø –Ω–µ –Ω–∞—à–µ–ª –æ—Ç–≤–µ—Ç–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö\".\n",
        "\n",
        "–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n",
        "{context}\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", SYSTEM_TEMPLATE),\n",
        "    (\"human\", \"{question}\"),\n",
        "])\n",
        "\n",
        "# LCEL chain –¥–ª—è Hybrid RAG\n",
        "hybrid_rag_chain = (\n",
        "    RunnablePassthrough.assign(\n",
        "        documents=lambda x: ensemble_retriever.invoke(x[\"question\"])\n",
        "    )\n",
        "    | RunnablePassthrough.assign(\n",
        "        answer=lambda x: (prompt | llm | StrOutputParser()).invoke({\n",
        "            \"context\": \"\\n\\n\".join(doc.page_content for doc in x[\"documents\"]),\n",
        "            \"question\": x[\"question\"]\n",
        "        })\n",
        "    )\n",
        "    | (lambda x: {\"answer\": x[\"answer\"], \"documents\": x[\"documents\"]})\n",
        ")\n",
        "\n",
        "print(\"‚úì Hybrid RAG chain –≥–æ—Ç–æ–≤\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –¢–µ—Å—Ç\n",
        "result = hybrid_rag_chain.invoke({\"question\": \"–ß—Ç–æ –Ω—É–∂–Ω–æ –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è –≤–∫–ª–∞–¥–∞?\"})\n",
        "print(f\"–û—Ç–≤–µ—Ç: {result['answer'][:200]}...\")\n",
        "print(f\"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(result['documents'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation Setup\n",
        "\n",
        "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
        "DATASET_NAME = \"SBERAGENTS_RAG_EVALUATION_DATASET_V1\"\n",
        "\n",
        "client = Client()\n",
        "datasets = list(client.list_datasets(dataset_name=DATASET_NAME))\n",
        "\n",
        "if datasets:\n",
        "    print(f\"‚úì –ù–∞–π–¥–µ–Ω –¥–∞—Ç–∞—Å–µ—Ç: {DATASET_NAME}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è –î–∞—Ç–∞—Å–µ—Ç {DATASET_NAME} –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞–π—Ç–µ –µ–≥–æ —Å–Ω–∞—á–∞–ª–∞.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAGAS –º–µ—Ç—Ä–∏–∫\n",
        "def init_ragas_metrics(metrics, llm, embedding):\n",
        "    for metric in metrics:\n",
        "        if isinstance(metric, MetricWithLLM):\n",
        "            metric.llm = llm\n",
        "        if isinstance(metric, MetricWithEmbeddings):\n",
        "            metric.embeddings = embedding\n",
        "        metric.init(RunConfig())\n",
        "\n",
        "langchain_llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
        "\n",
        "# –ò—Å–ø–æ–ª—å–∑—É–µ–º HuggingFace embeddings –¥–ª—è RAGAS (–ø–æ –∞–Ω–∞–ª–æ–≥–∏–∏ —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ embeddings)\n",
        "langchain_embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"intfloat/multilingual-e5-base\",\n",
        "    model_kwargs={'device': 'cpu'},\n",
        "    encode_kwargs={'normalize_embeddings': True}\n",
        ")\n",
        "\n",
        "ragas_metrics = [\n",
        "    Faithfulness(),\n",
        "    ResponseRelevancy(strictness=1),\n",
        "    AnswerCorrectness(),\n",
        "    AnswerSimilarity(),\n",
        "    ContextRecall(),\n",
        "    ContextPrecision(),\n",
        "]\n",
        "\n",
        "init_ragas_metrics(\n",
        "    ragas_metrics,\n",
        "    llm=LangchainLLMWrapper(langchain_llm),\n",
        "    embedding=LangchainEmbeddingsWrapper(langchain_embeddings),\n",
        ")\n",
        "\n",
        "ragas_run_config = RunConfig(max_workers=4, max_wait=180, max_retries=3)\n",
        "\n",
        "print(f\"‚úì RAGAS –º–µ—Ç—Ä–∏–∫–∏ –≥–æ—Ç–æ–≤—ã: {', '.join([m.name for m in ragas_metrics])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –§—É–Ω–∫—Ü–∏—è evaluation —Å RAGAS feedback –≤ LangSmith\n",
        "def evaluate_pipeline_with_ragas_feedback(pipeline_name: str, target: callable, dataset_name: str, metadata: dict = None):\n",
        "    if metadata is None:\n",
        "        metadata = {}\n",
        "    \n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Evaluation: {pipeline_name}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    questions, answers, contexts_list, ground_truths, run_ids = [], [], [], [], []\n",
        "    \n",
        "    print(f\"[1/3] –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞...\")\n",
        "    \n",
        "    for result in client.evaluate(\n",
        "        target,\n",
        "        data=dataset_name,\n",
        "        evaluators=[],\n",
        "        experiment_prefix=f\"rag-{pipeline_name}\",\n",
        "        metadata={\"pipeline\": pipeline_name, **metadata},\n",
        "        blocking=False,\n",
        "    ):\n",
        "        run = result[\"run\"]\n",
        "        example = result[\"example\"]\n",
        "        \n",
        "        questions.append(run.inputs.get(\"question\", \"\"))\n",
        "        answers.append(run.outputs.get(\"answer\", \"\"))\n",
        "        documents = run.outputs.get(\"documents\", [])\n",
        "        contexts_list.append([doc.page_content if hasattr(doc, 'page_content') else str(doc) for doc in documents])\n",
        "        ground_truths.append(example.outputs.get(\"answer\", \"\") if example else \"\")\n",
        "        run_ids.append(str(run.id))\n",
        "    \n",
        "    print(f\"‚úì –°–æ–±—Ä–∞–Ω–æ {len(questions)} –ø—Ä–∏–º–µ—Ä–æ–≤\")\n",
        "    \n",
        "    print(f\"[2/3] RAGAS evaluation...\")\n",
        "    \n",
        "    ragas_dataset = Dataset.from_dict({\n",
        "        \"question\": questions,\n",
        "        \"answer\": answers,\n",
        "        \"contexts\": contexts_list,\n",
        "        \"ground_truth\": ground_truths\n",
        "    })\n",
        "    \n",
        "    ragas_result = evaluate(ragas_dataset, metrics=ragas_metrics, run_config=ragas_run_config)\n",
        "    ragas_df = ragas_result.to_pandas()\n",
        "    \n",
        "    print(f\"‚úì –ú–µ—Ç—Ä–∏–∫–∏:\")\n",
        "    for metric in ragas_metrics:\n",
        "        if metric.name in ragas_df.columns:\n",
        "            print(f\"  {metric.name}: {ragas_df[metric.name].mean():.3f}\")\n",
        "    \n",
        "    print(f\"[3/3] –ó–∞–≥—Ä—É–∑–∫–∞ feedback –≤ LangSmith...\")\n",
        "    \n",
        "    for idx, run_id in enumerate(run_ids):\n",
        "        row = ragas_df.iloc[idx]\n",
        "        for metric in ragas_metrics:\n",
        "            if metric.name in row:\n",
        "                client.create_feedback(\n",
        "                    run_id=run_id,\n",
        "                    key=f\"{metric.name}\",\n",
        "                    score=float(row[metric.name]),\n",
        "                    comment=f\"RAGAS metric: {metric.name}\"\n",
        "                )\n",
        "    \n",
        "    print(f\"‚úì Feedback –∑–∞–≥—Ä—É–∂–µ–Ω\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "    \n",
        "    return {\"pipeline_name\": pipeline_name, \"ragas_result\": ragas_result, \"run_ids\": run_ids}\n",
        "\n",
        "print(\"‚úì –§—É–Ω–∫—Ü–∏—è evaluation –≥–æ—Ç–æ–≤–∞\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation Part 1: Hybrid RAG\n",
        "\n",
        "–ó–∞–ø—É—Å–∫–∞–µ–º evaluation –¥–ª—è Hybrid RAG (–±–µ–∑ reranking)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation –¥–ª—è Hybrid RAG\n",
        "hybrid_result = evaluate_pipeline_with_ragas_feedback(\n",
        "    pipeline_name=\"hybrid_rag\",\n",
        "    target=lambda inputs: hybrid_rag_chain.invoke(inputs),\n",
        "    dataset_name=DATASET_NAME,\n",
        "    metadata={\n",
        "        \"embeddings\": \"multilingual-e5-base (local)\",\n",
        "        \"retrieval\": \"Semantic + BM25 (RRF)\",\n",
        "        \"reranking\": \"none\",\n",
        "        \"llm\": \"gpt-4.1\"\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Cross-Encoder Reranking\n",
        "\n",
        "–î–æ–±–∞–≤–ª—è–µ–º reranking –ø–æ–≤–µ—Ä—Ö Hybrid RAG\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìö –ö–∞–∫ –≤—ã–±—Ä–∞—Ç—å cross-encoder –º–æ–¥–µ–ª—å:\n",
        "# 1. –û—Ç–∫—Ä–æ–π https://huggingface.co/cross-encoder/models?sort=downloads –∏–ª–∏ https://huggingface.co/models?other=cross-encoder&sort=downloads\n",
        "# 2. –ü—Ä–æ–≤–µ—Ä—å model card ‚Üí —è–∑—ã–∫–∏ ‚Üí –º–µ—Ç—Ä–∏–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)\n",
        "# 3. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã: multilingual > downloads > —Ä–∞–∑–º–µ—Ä\n",
        "#\n",
        "# –¢–æ–ø-3 –¥–ª—è multilingual:\n",
        "# 1. BAAI/bge-reranker-v2-m3 (568M, 2.2GB) - —Ç–æ–ø –∫–∞—á–µ—Å—Ç–≤–æ [—Ç—è–∂–µ–ª—ã–π]\n",
        "# 2. cross-encoder/mmarco-mMiniLMv2-L12-H384-v1 (117M, 470MB) ‚≠ê –ù–ê–® –í–´–ë–û–†\n",
        "#    –í—ã–±—Ä–∞–ª–∏: 14 —è–∑—ã–∫–æ–≤ (–≤–∫–ª—é—á–∞—è ru), –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π, –æ–±—É—á–µ–Ω –Ω–∞ mMARCO\n",
        "# 3. cross-encoder/ms-marco-MiniLM-L6-v2 (22M, 87MB) - —Ç–æ–ª—å–∫–æ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π [–±—ã—Å—Ç—Ä—ã–π]\n",
        "#\n",
        "# –ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –º–æ–¥–µ–ª—å: cross-encoder/mmarco-mMiniLMv2-L12-H384-v1\n",
        "# - –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: 117.6M\n",
        "# - –†–∞–∑–º–µ—Ä: ~470 MB\n",
        "# - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: XLM-RoBERTa\n",
        "# - –Ø–∑—ã–∫–∏: en, ar, zh, nl, fr, de, hi, it, ja, pt, ru, es, vi\n",
        "# - –û–±—É—á–µ–Ω –Ω–∞: mMARCO (multilingual MS MARCO)\n",
        "cross_encoder = CrossEncoder('cross-encoder/mmarco-mMiniLMv2-L12-H384-v1')\n",
        "\n",
        "def rerank_documents(query: str, documents: List[Document], top_k: int = 3):\n",
        "    \"\"\"Reranking –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å cross-encoder\"\"\"\n",
        "    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—ã (–∑–∞–ø—Ä–æ—Å, –¥–æ–∫—É–º–µ–Ω—Ç) –¥–ª—è cross-encoder\n",
        "    pairs = [(query, doc.page_content) for doc in documents]\n",
        "    \n",
        "    # Cross-encoder –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–π –ø–∞—Ä—ã\n",
        "    scores = cross_encoder.predict(pairs)\n",
        "    \n",
        "    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ —É–±—ã–≤–∞–Ω–∏—é score\n",
        "    ranked = sorted(zip(documents, scores), key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º top_k –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
        "    return ranked[:top_k]\n",
        "\n",
        "# LCEL chain —Å reranking\n",
        "hybrid_reranked_chain = (\n",
        "    RunnablePassthrough.assign(\n",
        "        ensemble_docs=lambda x: ensemble_retriever.invoke(x[\"question\"])\n",
        "    )\n",
        "    | RunnablePassthrough.assign(\n",
        "        documents=lambda x: [doc for doc, score in rerank_documents(\n",
        "            x[\"question\"], \n",
        "            x[\"ensemble_docs\"], \n",
        "            top_k=3\n",
        "        )]\n",
        "    )\n",
        "    | RunnablePassthrough.assign(\n",
        "        answer=lambda x: (prompt | llm | StrOutputParser()).invoke({\n",
        "            \"context\": \"\\n\\n\".join(doc.page_content for doc in x[\"documents\"]),\n",
        "            \"question\": x[\"question\"]\n",
        "        })\n",
        "    )\n",
        "    | (lambda x: {\"answer\": x[\"answer\"], \"documents\": x[\"documents\"]})\n",
        ")\n",
        "\n",
        "print(\"‚úì Hybrid RAG + Cross-encoder reranking –≥–æ—Ç–æ–≤\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –¢–µ—Å—Ç\n",
        "result = hybrid_reranked_chain.invoke({\"question\": \"–ß—Ç–æ –Ω—É–∂–Ω–æ –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è –≤–∫–ª–∞–¥–∞?\"})\n",
        "print(f\"–û—Ç–≤–µ—Ç: {result['answer']}\")\n",
        "print(f\"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(result['documents'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation Part 2: + Reranking\n",
        "\n",
        "–ó–∞–ø—É—Å–∫–∞–µ–º evaluation —Å reranking'–æ–º\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation –¥–ª—è Hybrid RAG + Reranking\n",
        "reranked_result = evaluate_pipeline_with_ragas_feedback(\n",
        "    pipeline_name=\"hybrid_rag_reranked\",\n",
        "    target=lambda inputs: hybrid_reranked_chain.invoke(inputs),\n",
        "    dataset_name=DATASET_NAME,\n",
        "    metadata={\n",
        "        \"embeddings\": \"multilingual-e5-base (local)\",\n",
        "        \"retrieval\": \"Semantic + BM25 (RRF)\",\n",
        "        \"reranking\": \"cross-encoder/mmarco-mMiniLMv2-L12-H384-v1 (multilingual)\",\n",
        "        \"llm\": \"gpt-4.1\"\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "\n",
        "–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–≤—É—Ö –ø–∞–π–ø–ª–∞–π–Ω–æ–≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫\n",
        "results_dict = {\n",
        "    \"Hybrid RAG\": hybrid_result[\"ragas_result\"].to_pandas(),\n",
        "    \"Hybrid + Reranking\": reranked_result[\"ragas_result\"].to_pandas()\n",
        "}\n",
        "\n",
        "comparison_data = []\n",
        "for name, df in results_dict.items():\n",
        "    row = {\"Pipeline\": name}\n",
        "    for metric in ragas_metrics:\n",
        "        if metric.name in df.columns:\n",
        "            row[metric.name] = df[metric.name].mean()\n",
        "    comparison_data.append(row)\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison_data)\n",
        "\n",
        "print(\"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤:\")\n",
        "print(df_comparison.to_string(index=False))\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "metric_names = [m.name for m in ragas_metrics if m.name in df_comparison.columns]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "x = np.arange(len(metric_names))\n",
        "width = 0.35\n",
        "\n",
        "hybrid_scores = [df_comparison[df_comparison['Pipeline'] == 'Hybrid RAG'][m].values[0] \n",
        "                 for m in metric_names]\n",
        "reranked_scores = [df_comparison[df_comparison['Pipeline'] == 'Hybrid + Reranking'][m].values[0] \n",
        "                   for m in metric_names]\n",
        "\n",
        "ax.bar(x - width/2, hybrid_scores, width, label='Hybrid RAG', alpha=0.8)\n",
        "ax.bar(x + width/2, reranked_scores, width, label='Hybrid + Reranking', alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('–ú–µ—Ç—Ä–∏–∫–∏')\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ: Hybrid RAG vs Hybrid + Reranking')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metric_names, rotation=45, ha='right')\n",
        "ax.legend()\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "ax.set_ylim(0, 1.0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úÖ Evaluation –∑–∞–≤–µ—Ä—à–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ LangSmith UI\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ò—Ç–æ–≥–∏\n",
        "\n",
        "**Part 1: Hybrid RAG (Semantic + BM25)**\n",
        "- –õ–æ–∫–∞–ª—å–Ω—ã–µ embeddings (multilingual-e5-base)\n",
        "- Ensemble retriever —Å RRF fusion\n",
        "- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ LangSmith\n",
        "\n",
        "**Part 2: + Cross-Encoder Reranking**\n",
        "- Cross-encoder reranking –ø–æ–≤–µ—Ä—Ö Hybrid retrieval\n",
        "- –£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∑–∞ —Å—á–µ—Ç –ø–µ—Ä–µ–æ—Ü–µ–Ω–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏\n",
        "- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫\n",
        "\n",
        "**–ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã:**\n",
        "- Hybrid retrieval –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç semantic –∏ keyword search\n",
        "- Cross-encoder —É–ª—É—á—à–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è\n",
        "- –í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–∞ CPU (–∫—Ä–æ–º–µ LLM)\n",
        "- LCEL —É–ø—Ä–æ—â–∞–µ—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
